{
    "400": {
        "file_id": 21,
        "content": "/RWKV-v3/verify.py",
        "type": "filepath"
    },
    "401": {
        "file_id": 21,
        "content": "RWKV Language Model is verified using GPT architecture, creating RWKV-GPT and RWKV-RNN models. Context data, input length, and model forward execution are performed on context tensor. Padding and batching done for compatibility with forward and backward groups. Model training forward pass executed, detaching and moving results to CPU before printing.",
        "type": "summary"
    },
    "402": {
        "file_id": 21,
        "content": "########################################################################################################\n# The RWKV Language Model - https://github.com/BlinkDL/RWKV-LM\n########################################################################################################\n# this is for verifying the results of different models and make sure they agree with each other\nimport numpy as np\nnp.set_printoptions(precision=4, suppress=True, linewidth=200)\nimport os\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\nRUN_DEVICE = 'cuda'\nimport torch\nfrom src.model_run import RWKV_RNN, RWKV_GPT\nfrom src.model import GPT, GPTConfig\nctx_len = 1024\nn_layer = 6\nn_embd = 512\nmodel_type = 'RWKV'\nmodel_name = 'trained-1'\nfrom src.utils import TOKENIZER\ntokenizer = TOKENIZER('vocab', UNKNOWN_CHAR=' ')\n########################################################################################################\nmodel_train = GPT(GPTConfig(tokenizer.vocab_size, ctx_len, model_type=model_type, n_layer=n_layer, n_embd=n_embd)).cuda()\nprint('loading ' + model_name)",
        "type": "code",
        "location": "/RWKV-v3/verify.py:1-31"
    },
    "403": {
        "file_id": 21,
        "content": "Loading and configuring the RWKV Language Model (RWKV-LM) for verification, using GPT architecture with specific configurations and tokenizer.",
        "type": "comment"
    },
    "404": {
        "file_id": 21,
        "content": "m2 = torch.load(model_name + '.pth', map_location=RUN_DEVICE)\nmodel_train.load_state_dict(m2)\nmodel_rnn = RWKV_RNN(model_name, RUN_DEVICE, model_type, n_layer, n_embd, ctx_len)\nmodel_gpt = RWKV_GPT(model_name, RUN_DEVICE, model_type, tokenizer.vocab_size, n_layer, n_embd, ctx_len).cuda()\n########################################################################################################\ncontext = '\\nIn a'\nctx = [tokenizer.stoi.get(s, tokenizer.UNKNOWN_CHAR) for s in context]\nprint(f'input len {len(ctx)} data {ctx}')\n########################################################################################################\nprint('\\nRWKV-GPT output')\nout = model_gpt.forward(torch.tensor(ctx).unsqueeze(0).cuda())[0].detach().cpu().numpy()\nprint(out)\nprint('\\nRWKV-RNN output')\nmodel_rnn.clear()\nsrc_len = len(ctx)\nfor i in range(src_len):\n    x = ctx[:i+1]\n    out = model_rnn.run(x)\n    if i < 3 or i >= src_len - 3:\n        print(torch.tensor(out).detach().cpu().numpy())\n    if i == 2:\n        print('...')\nprint('\\nRWKV-train output')",
        "type": "code",
        "location": "/RWKV-v3/verify.py:32-61"
    },
    "405": {
        "file_id": 21,
        "content": "Loading the model from a checkpoint file and creating both RWKV-GPT and RWKV-RNN models.\nPrinting input length and data for context.\nOutput of RWKV-GPT model using forward function on context tensor.\nOutput of RWKV-RNN model running on context with select indices printed.\nOutput of the train model running on context with select indices printed.",
        "type": "comment"
    },
    "406": {
        "file_id": 21,
        "content": "ctx += [0] * (ctx_len - src_len) # pad to ctx_len\nctx = [ctx] * 4 # increase batch size (to make it work with B_GROUP_FORWARD & B_GROUP_BACKWARD)\nout = model_train.forward(torch.tensor(ctx).cuda())[0][0][:src_len].detach().cpu().numpy()\nprint(out, '\\n')",
        "type": "code",
        "location": "/RWKV-v3/verify.py:62-65"
    },
    "407": {
        "file_id": 21,
        "content": "Padding the context list to match the length of source, then duplicating it to increase batch size for compatibility with forward and backward groups. Performs model training forward pass on padded context, detaches and moves result to CPU before printing.",
        "type": "comment"
    },
    "408": {
        "file_id": 22,
        "content": "/RWKV-v4/cuda/wkv_cuda.cu",
        "type": "filepath"
    },
    "409": {
        "file_id": 22,
        "content": "RWKV-v4's CUDA kernel performs RNN operations, gradient calculation, and avoids overflow with matrix multiplication. Efficient parallel execution techniques are used in cuda_forward and cuda_backward functions, optimizing register usage and ensuring proper block and thread configurations for GPU execution.",
        "type": "summary"
    },
    "410": {
        "file_id": 22,
        "content": "#include <stdio.h>\n#include <assert.h>\n#define MIN_VALUE (-1e38)\ntemplate <typename F>\n__global__ void kernel_forward(const int B, const int T, const int C,\n                               const F *__restrict__ const _w, const F *__restrict__ const _u, const F *__restrict__ const _k, const F *__restrict__ const _v,\n                               F *__restrict__ const _y) {\n    const int idx = blockIdx.x * blockDim.x + threadIdx.x;\n    const int _b = idx / C;\n    const int _c = idx % C;\n    const int _offset = _b * T * C + _c;\n    F u = _u[_c];\n    F w = _w[_c];\n    const F *__restrict__ const k = _k + _offset;\n    const F *__restrict__ const v = _v + _offset;\n    F *__restrict__ const y = _y + _offset;\n    F p = 0, q = 0, o = MIN_VALUE;\n    // p and q are running sums divided by exp(o) (to avoid overflows)\n    for (int i = 0; i < T; i++) {\n        const int ii = i * C;\n        F no = max(o, u + k[ii]);\n        F A = exp(o - no);\n        F B = exp(u + k[ii] - no);\n        y[ii] = (A * p + B * v[ii]) / (A * q + B);",
        "type": "code",
        "location": "/RWKV-v4/cuda/wkv_cuda.cu:1-29"
    },
    "411": {
        "file_id": 22,
        "content": "This code snippet defines a CUDA kernel function for the forward pass of a recurrent neural network (RNN). The function takes input and weight tensors as arguments, performs matrix multiplications, and accumulates results using running sums to avoid overflows. The result is stored in output tensor y.",
        "type": "comment"
    },
    "412": {
        "file_id": 22,
        "content": "        no = max(w + o, k[ii]);\n        A = exp(w + o - no);\n        B = exp(k[ii] - no);\n        p = A * p + B * v[ii];\n        q = A * q + B;\n        o = no;\n    }\n}\ntemplate <typename F>\n__global__ void kernel_backward(const int B, const int T, const int C,\n                                const F *__restrict__ const _w, const F *__restrict__ const _u, const F *__restrict__ const _k, const F *__restrict__ const _v, const F *__restrict__ const _gy,\n                                F *__restrict__ const _gw, F *__restrict__ const _gu, F *__restrict__ const _gk, F *__restrict__ const _gv) {\n    const int idx = blockIdx.x * blockDim.x + threadIdx.x;\n    const int _b = idx / C;\n    const int _c = idx % C;\n    const int _offset = _b * T * C + _c;\n    F u = _u[_c];\n    F w = _w[_c];\n    const F *__restrict__ const k = _k + _offset;\n    const F *__restrict__ const v = _v + _offset;\n    const F *__restrict__ const gy = _gy + _offset;\n    F *__restrict__ const gk = _gk + _offset;\n    F *__restrict__ const gv = _gv + _offset;",
        "type": "code",
        "location": "/RWKV-v4/cuda/wkv_cuda.cu:31-56"
    },
    "413": {
        "file_id": 22,
        "content": "Kernel function for backward propagation in RWKV-v4. Calculates gradients for weight matrix w, input u and key matrix k. Uses blockIdx and threadIdx to calculate offsets for accessing data.",
        "type": "comment"
    },
    "414": {
        "file_id": 22,
        "content": "    F y[Tmax], z[Tmax], zexp[Tmax];\n    F gw = 0, gu = 0;\n    F p = 0, q = 0;\n    F dpdw = 0, dqdw = 0;\n    F o = MIN_VALUE;\n    for (int i = 0; i < T; i++) {\n        const int ii = i * C;\n        F no = max(o, k[ii] + u);\n        F A = exp(o - no);\n        F B = exp(k[ii] + u - no);\n        F num = A * p + B * v[ii];\n        F iden = 1 / (A * q + B);\n        y[i] = num * iden;\n        z[i] = iden;\n        zexp[i] = k[ii] + u - no;\n        gw += gy[ii] * (dpdw - dqdw * y[i]) * iden * A;\n        gu += gy[ii] * (v[ii] - y[i]) * B * iden;\n        no = max(w + o, k[ii]);\n        A = exp(w + o - no);\n        B = exp(k[ii] - no);\n        dpdw = A * (p + dpdw);\n        dqdw = A * (q + dqdw);\n        p = A * p + B * v[ii];\n        q = A * q + B;\n        o = no;\n    }\n    F gp = 0, gq = 0;\n    o = MIN_VALUE;\n    for (int i = T - 1; i >= 0; i--) {\n        const int ii = i * C;\n        F A = gy[ii] * z[i] * exp(zexp[i]);\n        F B = exp(k[ii] + o);\n        gk[ii] = A * (v[ii] - y[i]) + B * (gp * v[ii] + gq);\n        gv[ii] = A + B * gp;",
        "type": "code",
        "location": "/RWKV-v4/cuda/wkv_cuda.cu:58-97"
    },
    "415": {
        "file_id": 22,
        "content": "This code calculates the gradients of model parameters by iterating through a dataset, updating intermediate variables, and storing gradients in gk and gv arrays. It uses matrix multiplication and exponential operations.",
        "type": "comment"
    },
    "416": {
        "file_id": 22,
        "content": "        F no = max(w + o, zexp[i] - k[ii] - u);\n        A = exp(w + o - no);\n        B = gy[ii] * z[i] * exp(zexp[i] - k[ii] - u - no);\n        gp = A * gp + B;\n        gq = A * gq - B * y[i];\n        o = no;\n    }\n    // Multiply by w because the w -> -exp(w) preprocessing is halfway in the backwards pass, even though it's not in the forward pass\n    const int _offsetBC = _b * C + _c;\n    _gw[_offsetBC] += gw * _w[_c];\n    _gu[_offsetBC] += gu;\n}\nvoid cuda_forward(int B, int T, int C, float *w, float *u, float *k, float *v, float *y) {\n    dim3 threadsPerBlock( min(C, 32) ); // requires --maxrregcount 60 for optimal performance\n    assert(B * C % threadsPerBlock.x == 0);\n    dim3 numBlocks(B * C / threadsPerBlock.x);\n    kernel_forward<<<numBlocks, threadsPerBlock>>>(B, T, C, w, u, k, v, y);\n}\nvoid cuda_backward(int B, int T, int C, float *w, float *u, float *k, float *v, float *gy, float *gw, float *gu, float *gk, float *gv) {\n    dim3 threadsPerBlock( min(C, 32) ); // requires --maxrregcount 60 for optimal performance",
        "type": "code",
        "location": "/RWKV-v4/cuda/wkv_cuda.cu:99-121"
    },
    "417": {
        "file_id": 22,
        "content": "This code is a part of the RWKV-v4 library, specifically the cuda_forward and cuda_backward functions for CUDA implementation. It involves setting up blocks and threads based on the given dimensions B, T, and C. The kernels kernel_forward and kernel_backward are launched with appropriate block and thread configurations to perform matrix operations in parallel. This code utilizes an optimal number of registers and asserts that B * C is divisible by the chosen number of threads per block for efficient execution.",
        "type": "comment"
    },
    "418": {
        "file_id": 22,
        "content": "    assert(B * C % threadsPerBlock.x == 0);\n    dim3 numBlocks(B * C / threadsPerBlock.x);\n    kernel_backward<<<numBlocks, threadsPerBlock>>>(B, T, C, w, u, k, v, gy, gw, gu, gk, gv);\n}",
        "type": "code",
        "location": "/RWKV-v4/cuda/wkv_cuda.cu:122-125"
    },
    "419": {
        "file_id": 22,
        "content": "This code ensures that the number of blocks is an integer multiple of threads per block, then launches a kernel function for backward computation. It uses B, C, and threadsPerBlock parameters to determine the number of blocks and threads per block for efficient GPU execution.",
        "type": "comment"
    },
    "420": {
        "file_id": 23,
        "content": "/RWKV-v4/cuda/wkv_op.cpp",
        "type": "filepath"
    },
    "421": {
        "file_id": 23,
        "content": "The code defines C++ functions for the forward and backward passes of a WKV model in RWKV-LM/RWKV-v4, utilizing PyTorch's torch::Tensor class and CUDA kernels on GPU.",
        "type": "summary"
    },
    "422": {
        "file_id": 23,
        "content": "#include <torch/extension.h>\nvoid cuda_forward(int B, int T, int C, float *w, float *u, float *k, float *v, float *y);\nvoid cuda_backward(int B, int T, int C, float *w, float *u, float *k, float *v, float *gy, float *gw, float *gu, float *gk, float *gv);\nvoid forward(int64_t B, int64_t T, int64_t C, torch::Tensor &w, torch::Tensor &u, torch::Tensor &k, torch::Tensor &v, torch::Tensor &y) {\n    cuda_forward(B, T, C, w.data_ptr<float>(), u.data_ptr<float>(), k.data_ptr<float>(), v.data_ptr<float>(), y.data_ptr<float>());\n}\nvoid backward(int64_t B, int64_t T, int64_t C, torch::Tensor &w, torch::Tensor &u, torch::Tensor &k, torch::Tensor &v, torch::Tensor &gy, torch::Tensor &gw, torch::Tensor &gu, torch::Tensor &gk, torch::Tensor &gv) {\n    cuda_backward(B, T, C, w.data_ptr<float>(), u.data_ptr<float>(), k.data_ptr<float>(), v.data_ptr<float>(), gy.data_ptr<float>(), gw.data_ptr<float>(), gu.data_ptr<float>(), gk.data_ptr<float>(), gv.data_ptr<float>());\n}\nPYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {\n    m.def(\"forward\", &forward, \"wkv forward\");",
        "type": "code",
        "location": "/RWKV-v4/cuda/wkv_op.cpp:1-14"
    },
    "423": {
        "file_id": 23,
        "content": "This code defines a C++ function for the forward pass of the WaveGrad RWKV model, and a backward pass for gradient calculation. It uses the torch::Tensor class from PyTorch library to handle tensors and wraps the CUDA kernels with torch::extension to enable GPU computation.",
        "type": "comment"
    },
    "424": {
        "file_id": 23,
        "content": "    m.def(\"backward\", &backward, \"wkv backward\");\n}\nTORCH_LIBRARY(wkv, m) {\n    m.def(\"forward\", forward);\n    m.def(\"backward\", backward);\n}",
        "type": "code",
        "location": "/RWKV-v4/cuda/wkv_op.cpp:15-21"
    },
    "425": {
        "file_id": 23,
        "content": "The code is defining C++ functions for the forward and backward passes of a Wavelet Quantized Variational Kalman Filter (WKV) model in the RWKV-LM/RWKV-v4/cuda/wkv_op.cpp file, which are then exported as bindings through Torch library with names \"forward\" and \"backward\".",
        "type": "comment"
    },
    "426": {
        "file_id": 24,
        "content": "/RWKV-v4/run.py",
        "type": "filepath"
    },
    "427": {
        "file_id": 24,
        "content": "This code utilizes the RWKV Language Model for text generation, setting up parameters and initializing the model. It tokenizes prompts, performs multiple trials, calculates logits, handles special cases, prints tokens, and saves/loads model states.",
        "type": "summary"
    },
    "428": {
        "file_id": 24,
        "content": "########################################################################################################\n# The RWKV Language Model - https://github.com/BlinkDL/RWKV-LM\n########################################################################################################\nimport numpy as np\nimport math, os\nimport time\nimport types\nimport copy\nimport torch\nfrom torch.nn import functional as F\nfrom src.utils import TOKENIZER, Dataset\ntorch.backends.cudnn.benchmark = True\ntorch.backends.cudnn.allow_tf32 = True\ntorch.backends.cuda.matmul.allow_tf32 = True\nnp.set_printoptions(precision=4, suppress=True, linewidth=200)\n########################################################################################################\n# Step 1: set model\n# \n# Set TOKEN_MODE to 'char' or 'bpe' if the model is trained by 'train.py' from scratch.\n#\n# Set TOKEN_MODE to 'pile' if you want to test pre-trained pile models.\n########################################################################################################\nTOKEN_MODE = 'char' # char / bpe / pile",
        "type": "code",
        "location": "/RWKV-v4/run.py:1-26"
    },
    "429": {
        "file_id": 24,
        "content": "This code is importing necessary libraries and modules for the RWKV Language Model. It sets the TOKEN_MODE variable to either 'char', 'bpe', or 'pile' depending on whether the model is trained from scratch, pre-trained pile models are being tested, etc. This helps set up the appropriate configuration for running the model.",
        "type": "comment"
    },
    "430": {
        "file_id": 24,
        "content": "n_layer = 6\nn_embd = 512\nctx_len = 1024\nif TOKEN_MODE == 'char':\n    MODEL_NAME = 'trained-500'  # your trained model\n    WORD_NAME = 'vocab'         # the .json vocab (generated by train.py)\n    # set UNKNOWN_CHAR to the rarest token in your vocab.json, and all unknown tokens in your prompt will be denoted by it\n    UNKNOWN_CHAR = ' '          # here we just set it to ' ' for simplicity\nelif TOKEN_MODE == 'bpe':\n    MODEL_NAME = 'trained-500'  # your trained model\n    WORD_NAME = ['model-vocab.json', 'model-merges.txt'] # [vocab, merge] for your BPE model\n    UNKNOWN_CHAR = None\nelif TOKEN_MODE == 'pile':\n    WORD_NAME = ['20B_tokenizer.json', '20B_tokenizer.json']\n    UNKNOWN_CHAR = None\n    #---> you can set MODEL_NAME to your fine-tuned model <---\n    MODEL_NAME = 'RWKV-4-Pile-169M-20220807-8023'\n    # MODEL_NAME = 'trained-11'\n    n_layer = 12\n    n_embd = 768\n    ctx_len = 1024\n    # MODEL_NAME = 'RWKV-4-Pile-430M-20220808-8066'\n    # n_layer = 24\n    # n_embd = 1024\n    # ctx_len = 1024\n    # MODEL_NAME = 'RWKV-4-Pile-1B5-20220903-8040'",
        "type": "code",
        "location": "/RWKV-v4/run.py:28-60"
    },
    "431": {
        "file_id": 24,
        "content": "This code is responsible for setting the necessary parameters and model name based on the tokenization mode. The modes include character, byte-pair encoding (BPE), and Pile. If using a pre-trained RWKV model, it allows specifying a fine-tuned model for better performance. Different model architectures like BERT, RoBERTa, and GPT are used depending on the mode. The parameters n_layer, n_embd, and ctx_len define the number of layers, embedding dimensions, and context length respectively for the chosen model.",
        "type": "comment"
    },
    "432": {
        "file_id": 24,
        "content": "    # n_layer = 24\n    # n_embd = 2048\n    # ctx_len = 1024    \nos.environ['RWKV_FLOAT_MODE'] = 'fp32'  # 'bf16' / 'fp16' / 'fp32' (note: only using fp32 at this moment)\nos.environ['RWKV_RUN_DEVICE'] = 'cpu'   # 'cpu' (already very fast) or 'cuda'\nmodel_type = 'RWKV' # 'RWKV' or 'RWKV-ffnPre'\n########################################################################################################\n# Step 2: set prompt & sampling stuffs\n########################################################################################################\n# context = 'A'\n# context = \"\\nIn the\"\n# context = '\\nSugar:'\ncontext = '\\nIn a shocking finding, scientist discovered a herd of dragons living in a remote, previously unexplored valley, in Tibet. Even more surprising to the researchers was the fact that the dragons spoke perfect Chinese.'\nNUM_TRIALS = 999\nLENGTH_PER_TRIAL = 333\nTEMPERATURE = 1.0\ntop_p = 0.7\ntop_p_newline = 0.9 # only used in TOKEN_MODE = char\nDEBUG_DEBUG = False  # True False --> show softmax output\n####",
        "type": "code",
        "location": "/RWKV-v4/run.py:61-87"
    },
    "433": {
        "file_id": 24,
        "content": "The code is setting the environment variables for the RWKV model, specifying the model type, and providing the prompt and sampling parameters. The model is currently using fp32 (floating-point arithmetic) and running on the CPU. The prompt provided is a text describing the discovery of Chinese-speaking dragons in Tibet. The code will perform 999 trials, each producing output of length 333, with temperature set to 1.0 for sampling and top_p set to 0.7 and 0.9 for softmax output.",
        "type": "comment"
    },
    "434": {
        "file_id": 24,
        "content": "####################################################################################################\nprint(f'Loading {MODEL_NAME}...')\nfrom src.model_run import RWKV_RNN\nmodel = RWKV_RNN(MODEL_NAME, os.environ['RWKV_RUN_DEVICE'], model_type, n_layer, n_embd, ctx_len)\ntokenizer = TOKENIZER(WORD_NAME, UNKNOWN_CHAR=UNKNOWN_CHAR)\n########################################################################################################\nif tokenizer.charMode:\n    context = tokenizer.refine_context(context)\n    ctx = [tokenizer.stoi.get(s, tokenizer.UNKNOWN_CHAR) for s in context]\nelse:\n    ctx = tokenizer.tokenizer.encode(context)\nsrc_len = len(ctx)\nsrc_ctx = ctx.copy()\nprint('\\nYour prompt has ' + str(src_len) + ' tokens.')\nprint('\\n--> Currently the first run takes a while if your prompt is long, as we are using RNN to process the prompt. Use GPT to build the hidden state for better speed. <--\\n')\nfor TRIAL in range(1 if DEBUG_DEBUG else NUM_TRIALS):\n    t_begin = time.time_ns()\n    print(('-' * 30) + context, end='')",
        "type": "code",
        "location": "/RWKV-v4/run.py:87-109"
    },
    "435": {
        "file_id": 24,
        "content": "Loading the specified RWKV model, creating a tokenizer for text processing, refining context if in character mode, converting context to tokens, printing the number of tokens in prompt, informing about the time taken to process long prompts with RNN or using GPT for faster speed, and starting a loop for multiple trials.",
        "type": "comment"
    },
    "436": {
        "file_id": 24,
        "content": "    ctx = src_ctx.copy()\n    model.clear()\n    if TRIAL == 0:\n        init_state = types.SimpleNamespace()\n        for i in range(src_len):\n            x = ctx[:i+1]\n            if i == src_len - 1:\n                init_state.out = model.run(x)\n            else:\n                model.run(x)\n        model.save(init_state)\n    else:\n        model.load(init_state)\n    for i in range(src_len, src_len + (1 if DEBUG_DEBUG else LENGTH_PER_TRIAL)):\n        x = ctx[:i+1]\n        x = x[-ctx_len:]\n        if i == src_len:\n            out = copy.deepcopy(init_state.out)\n        else:\n            out = model.run(x)\n        if DEBUG_DEBUG:\n            print('model', np.array(x), '==>', np.array(\n                out), np.max(out), np.min(out))\n        if TOKEN_MODE == 'pile':\n            out[0] = -999999999  # disable <|endoftext|>\n        char = tokenizer.sample_logits(out, x, ctx_len, temperature=TEMPERATURE,\n                                       top_p_usual=top_p, top_p_newline=top_p_newline)\n        char = char.item()\n        if tokenizer.charMode:",
        "type": "code",
        "location": "/RWKV-v4/run.py:110-142"
    },
    "437": {
        "file_id": 24,
        "content": "This code initializes a model and its state, then generates text based on the input sequence. It saves and loads the model's state for subsequent trials, calculates logits for character sampling, and handles special cases like disabling <|endoftext|>. The DEBUG_DEBUG print statement displays output statistics if enabled.",
        "type": "comment"
    },
    "438": {
        "file_id": 24,
        "content": "            print(tokenizer.itos[int(char)], end='', flush=True)\n        else:\n            print(tokenizer.tokenizer.decode(int(char)), end='', flush=True)\n        ctx += [char]\n    t_end = time.time_ns()\n    print(\"\\n----------\", round((t_end - t_begin) / (10 ** 9), 2), end='s ')",
        "type": "code",
        "location": "/RWKV-v4/run.py:143-149"
    },
    "439": {
        "file_id": 24,
        "content": "The code is printing each token in a sequence using either the integer representation or the decoded version from the tokenizer, and storing each character in the ctx list. It also measures the time taken for this process and prints it in seconds at the end.",
        "type": "comment"
    },
    "440": {
        "file_id": 25,
        "content": "/RWKV-v4/src/binidx.py",
        "type": "filepath"
    },
    "441": {
        "file_id": 25,
        "content": "The code defines a class \"MMapIndexedDataset\" with indexing methods and binary indexing functions for datasets, loading binary data from file paths using numpy's memmap. It supports setting document index and checking file existence.",
        "type": "summary"
    },
    "442": {
        "file_id": 25,
        "content": "from lib2to3.pgen2 import token\nimport os\nimport torch\nimport numpy as np\nimport shutil\nimport struct\nfrom functools import lru_cache\nfrom itertools import accumulate\ndef print_rank_0(*message):\n    \"\"\"If distributed is initialized print only on rank 0.\"\"\"\n    if torch.distributed.is_initialized():\n        if torch.distributed.get_rank() == 0:\n            print(*message, flush=True)\n    else:\n        print(*message, flush=True)\ndef _warmup_mmap_file(path):\n    pass\n    # with open(path, \"rb\") as stream:\n    #     while stream.read(100 * 1024 * 1024):\n    #         pass\ndtypes = {\n    1: np.uint8,\n    2: np.int8,\n    3: np.int16,\n    4: np.int32,\n    5: np.int64,\n    6: float,\n    7: np.double,\n    8: np.uint16,\n}\ndef code(dtype):\n    for k in dtypes.keys():\n        if dtypes[k] == dtype:\n            return k\n    raise ValueError(dtype)\ndef index_file_path(prefix_path):\n    return prefix_path + \".idx\"\ndef data_file_path(prefix_path):\n    return prefix_path + \".bin\"\nclass MMapIndexedDataset(torch.utils.data.Dataset):\n    class Index(object):",
        "type": "code",
        "location": "/RWKV-v4/src/binidx.py:1-48"
    },
    "443": {
        "file_id": 25,
        "content": "This code is importing necessary libraries and defining functions for indexed datasets. It defines a class \"MMapIndexedDataset\" with an inner class \"Index\". The file includes utility functions like _warmup_mmap_file, print_rank_0, index_file_path, data_file_path, and code which handle reading and manipulating binary data from files. It also defines dtypes dictionary mapping numerical types to their respective codes.",
        "type": "comment"
    },
    "444": {
        "file_id": 25,
        "content": "        _HDR_MAGIC = b\"MMIDIDX\\x00\\x00\"\n        def __init__(self, path, skip_warmup=False):\n            with open(path, \"rb\") as stream:\n                magic_test = stream.read(9)\n                assert self._HDR_MAGIC == magic_test, (\n                    \"Index file doesn't match expected format. \"\n                    \"Make sure that --dataset-impl is configured properly.\"\n                )\n                # Little endian unsigned 64 Bit integer\n                version = struct.unpack(\"<Q\", stream.read(8))\n                assert (1,) == version\n                # Little endian unsigned 8 Bit integer\n                (dtype_code,) = struct.unpack(\"<B\", stream.read(1))\n                self._dtype = dtypes[dtype_code]\n                self._dtype_size = self._dtype().itemsize\n                self._len = struct.unpack(\"<Q\", stream.read(8))[0]\n                self._doc_count = struct.unpack(\"<Q\", stream.read(8))[0]\n                offset = stream.tell()\n            if not skip_warmup:\n                print_rank_0(\"    warming up index mmap file...\")",
        "type": "code",
        "location": "/RWKV-v4/src/binidx.py:49-72"
    },
    "445": {
        "file_id": 25,
        "content": "This code is initializing a class that reads an index file, checking if it matches the expected format, and storing relevant information such as dtype, dtype size, length, and document count. The skip_warmup parameter allows for optional warming up of the index file.",
        "type": "comment"
    },
    "446": {
        "file_id": 25,
        "content": "                _warmup_mmap_file(path)\n            self._bin_buffer_mmap = np.memmap(path, mode=\"r\", order=\"C\")\n            self._bin_buffer = memoryview(self._bin_buffer_mmap)\n            print_rank_0(\"    reading sizes...\")\n            self._sizes = np.frombuffer(\n                self._bin_buffer, dtype=np.int32, count=self._len, offset=offset\n            )\n            print_rank_0(\"    reading pointers...\")\n            self._pointers = np.frombuffer(\n                self._bin_buffer,\n                dtype=np.int64,\n                count=self._len,\n                offset=offset + self._sizes.nbytes,\n            )\n            print_rank_0(\"    reading document index...\")\n            self._doc_idx = np.frombuffer(\n                self._bin_buffer,\n                dtype=np.int64,\n                count=self._doc_count,\n                offset=offset + self._sizes.nbytes + self._pointers.nbytes,\n            )\n        def __del__(self):\n            self._bin_buffer_mmap._mmap.close()\n            del self._bin_buffer_mmap",
        "type": "code",
        "location": "/RWKV-v4/src/binidx.py:73-98"
    },
    "447": {
        "file_id": 25,
        "content": "The code is loading a binary file into memory using numpy's memmap. It reads sizes, pointers, and document index from the binary file, and finally closes the memory-mapped file in the destructor.",
        "type": "comment"
    },
    "448": {
        "file_id": 25,
        "content": "        @property\n        def dtype(self):\n            return self._dtype\n        @property\n        def sizes(self):\n            return self._sizes\n        @property\n        def doc_idx(self):\n            return self._doc_idx\n        @lru_cache(maxsize=8)\n        def __getitem__(self, i):\n            return self._pointers[i], self._sizes[i]\n        def __len__(self):\n            return self._len\n    def __init__(self, path, skip_warmup=False):\n        super().__init__()\n        self._path = None\n        self._index = None\n        self._bin_buffer = None\n        self._do_init(path, skip_warmup)\n    def __getstate__(self):\n        return self._path\n    def __setstate__(self, state):\n        self._do_init(state)\n    def _do_init(self, path, skip_warmup):\n        self._path = path\n        self._index = self.Index(index_file_path(self._path), skip_warmup)\n        if not skip_warmup:\n            print_rank_0(\"    warming up data mmap file...\")\n            _warmup_mmap_file(data_file_path(self._path))\n        print_rank_0(\"    creating numpy buffer of mmap...\")",
        "type": "code",
        "location": "/RWKV-v4/src/binidx.py:100-141"
    },
    "449": {
        "file_id": 25,
        "content": "This code defines a class for loading and accessing binary data from file paths. It has properties for dtype, sizes, and doc_idx, and provides getitem and len methods. The class also initializes itself with the given path and optionally skips warmup if specified. The __getstate__ and __setstate__ functions are used to serialize and deserialize the object's state, respectively.",
        "type": "comment"
    },
    "450": {
        "file_id": 25,
        "content": "        self._bin_buffer_mmap = np.memmap(\n            data_file_path(self._path), mode=\"r\", order=\"C\"\n        )\n        print_rank_0(\"    creating memory view of numpy buffer...\")\n        self._bin_buffer = memoryview(self._bin_buffer_mmap)\n    def __del__(self):\n        self._bin_buffer_mmap._mmap.close()\n        del self._bin_buffer_mmap\n        del self._index\n    def __len__(self):\n        return len(self._index)\n    # @lru_cache(maxsize=8)\n    def __getitem__(self, idx):\n        if isinstance(idx, int):\n            ptr, size = self._index[idx]\n            np_array = np.frombuffer(\n                self._bin_buffer, dtype=self._index.dtype, count=size, offset=ptr\n            )\n            return np_array\n        elif isinstance(idx, slice):\n            start, stop, step = idx.indices(len(self))\n            if step != 1:\n                raise ValueError(\n                    \"Slices into indexed_dataset must be contiguous\")\n            ptr = self._index._pointers[start]\n            sizes = self._index._sizes[idx]",
        "type": "code",
        "location": "/RWKV-v4/src/binidx.py:142-170"
    },
    "451": {
        "file_id": 25,
        "content": "This code creates a memory view of a numpy buffer and closes the mmap on deletion. It also defines the length, getitem, and del methods for an indexed dataset. The __getitem__ method allows accessing elements based on integer or slice indices, but raises a ValueError if the slice is not contiguous.",
        "type": "comment"
    },
    "452": {
        "file_id": 25,
        "content": "            offsets = list(accumulate(sizes))\n            total_size = sum(sizes)\n            np_array = np.frombuffer(\n                self._bin_buffer, dtype=self._index.dtype, count=total_size, offset=ptr\n            )\n            sents = np.split(np_array, offsets[:-1])\n            return sents\n    def get(self, idx, offset=0, length=None):\n        \"\"\"Retrieves a single item from the dataset with the option to only\n        return a portion of the item.\n        get(idx) is the same as [idx] but get() does not support slicing.\n        \"\"\"\n        ptr, size = self._index[idx]\n        if length is None:\n            length = size - offset\n        ptr += offset * np.dtype(self._index.dtype).itemsize\n        np_array = np.frombuffer(\n            self._bin_buffer, dtype=self._index.dtype, count=length, offset=ptr\n        )\n        return np_array\n    @property\n    def sizes(self):\n        return self._index.sizes\n    @property\n    def doc_idx(self):\n        return self._index.doc_idx\n    def get_doc_idx(self):\n        return self._index._doc_idx",
        "type": "code",
        "location": "/RWKV-v4/src/binidx.py:171-203"
    },
    "453": {
        "file_id": 25,
        "content": "This code defines two functions related to binary indexing for a dataset. The first function, \"binidx\", splits an array of sizes into offsets and creates a numpy array from the bin buffer with the specified total size and offset. The second function, \"get\", retrieves a single item from the dataset by using the provided index and optional offset and length parameters to extract a portion of the item. It also provides properties for accessing sizes and document indices.",
        "type": "comment"
    },
    "454": {
        "file_id": 25,
        "content": "    def set_doc_idx(self, doc_idx_):\n        self._index._doc_idx = doc_idx_\n    @property\n    def supports_prefetch(self):\n        return False\n    @staticmethod\n    def exists(path):\n        return os.path.exists(index_file_path(path)) and os.path.exists(\n            data_file_path(path)\n        )",
        "type": "code",
        "location": "/RWKV-v4/src/binidx.py:205-216"
    },
    "455": {
        "file_id": 25,
        "content": "Function set_doc_idx sets the document index for the object, while supports_prefetch returns False. The exists function checks if both index and data files exist in the given path.",
        "type": "comment"
    },
    "456": {
        "file_id": 26,
        "content": "/RWKV-v4/src/model.py",
        "type": "filepath"
    },
    "457": {
        "file_id": 26,
        "content": "This code uses CUDA kernels, fancy initialization, and attention mechanism layers for RWKV models. It implements a time-mixing channel model with custom GPT layers, layer normalization, attention, feed-forward layers, and DeepSpeed's optimizer for improved performance.",
        "type": "summary"
    },
    "458": {
        "file_id": 26,
        "content": "########################################################################################################\n# The RWKV Language Model - https://github.com/BlinkDL/RWKV-LM\n########################################################################################################\nimport math, os\nimport numpy as np\nimport logging\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\ntry:\n    from deepspeed.ops.adam import FusedAdam\nexcept:\n    pass # some poor windows users cant install deepspeed\nlogger = logging.getLogger(__name__)\nRWKV_HEAD_QK_DIM = 0\nprint(f'\\nRWKV_HEAD_QK_DIM {RWKV_HEAD_QK_DIM}\\n')\nclass L2Wrap(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, loss, y):\n        ctx.save_for_backward(y)\n        return loss\n    @staticmethod\n    def backward(ctx, grad_output):\n        y = ctx.saved_tensors[0]\n        # to encourage the logits to be close to 0\n        factor = 1e-4 / (y.shape[0] * y.shape[1])\n        maxx, ids = torch.max(y, -1, keepdim=True)\n        gy = torch.zeros_like(y)",
        "type": "code",
        "location": "/RWKV-v4/src/model.py:1-32"
    },
    "459": {
        "file_id": 26,
        "content": "This code imports necessary libraries and defines a function called L2Wrap for calculating the loss. It also initializes RWKV_HEAD_QK_DIM variable and begins defining a class likely to be used in model training. The class uses the L2Wrap function to encourage logits to be close to 0.",
        "type": "comment"
    },
    "460": {
        "file_id": 26,
        "content": "        gy.scatter_(-1, ids, maxx * factor)\n        return (grad_output, gy)\n########################################################################################################\n# CUDA Kernel\n########################################################################################################\nT_MAX = 1024 # increase this if your ctx_len is long [NOTE: TAKES LOTS OF VRAM!]\n# it's possible to go beyond CUDA limitations if you slice the ctx and pass the hidden state in each slice\nfrom torch.utils.cpp_extension import load\nwkv_cuda = load(name=\"wkv\", sources=[\"cuda/wkv_op.cpp\", \"cuda/wkv_cuda.cu\"],\n                verbose=True, extra_cuda_cflags=['-res-usage', '--maxrregcount 60', '--use_fast_math', '-O3', '-Xptxas -O3', f'-DTmax={T_MAX}'])\nclass WKV(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, B, T, C, w, u, k, v):\n        ctx.B = B\n        ctx.T = T\n        ctx.C = C\n        assert T <= T_MAX\n        assert B * C % min(C, 1024) == 0\n        if '32' in os.environ['RWKV_FLOAT_MODE']:",
        "type": "code",
        "location": "/RWKV-v4/src/model.py:33-55"
    },
    "461": {
        "file_id": 26,
        "content": "This code defines a WKV class that uses the wkv_op.cpp and wkv_cuda.cu CUDA kernel files to perform computations on input B, T, C, w, u, k, and v. The function checks if T is within the maximum allowed value (T_MAX) and if the product of B and C is divisible by the smaller of B and C. If these conditions are met, it proceeds with further computations using a 32-bit floating point mode if '32' is present in the RWKV_FLOAT_MODE environment variable.",
        "type": "comment"
    },
    "462": {
        "file_id": 26,
        "content": "            w = -torch.exp(w.contiguous())\n            u = u.contiguous()\n            k = k.contiguous()\n            v = v.contiguous()\n        else:\n            w = -torch.exp(w.float().contiguous())\n            u = u.float().contiguous()\n            k = k.float().contiguous()\n            v = v.float().contiguous()\n        ctx.save_for_backward(w, u, k, v)\n        y = torch.empty((B, T, C), device='cuda', memory_format=torch.contiguous_format)\n        wkv_cuda.forward(B, T, C, w, u, k, v, y)\n        if '32' in os.environ['RWKV_FLOAT_MODE']:\n            return y\n        elif os.environ['RWKV_FLOAT_MODE'] == 'fp16':\n            return y.half()\n        elif os.environ['RWKV_FLOAT_MODE'] == 'bf16':\n            return y.bfloat16()\n    @staticmethod\n    def backward(ctx, gy):\n        B = ctx.B\n        T = ctx.T\n        C = ctx.C\n        assert T <= T_MAX\n        assert B * C % min(C, 1024) == 0\n        w, u, k, v = ctx.saved_tensors\n        gw = torch.zeros((B, C), device='cuda').contiguous()\n        gu = torch.zeros((B, C), device='cuda').contiguous()",
        "type": "code",
        "location": "/RWKV-v4/src/model.py:56-84"
    },
    "463": {
        "file_id": 26,
        "content": "This code snippet initializes tensors and handles different float modes for model forward pass. It saves tensors for backward pass, ensures correct shape and alignment, and returns the result based on the specified float mode. The backward method performs cleanup by creating zeros tensors for gradients and asserts that certain conditions are met before proceeding with calculations.",
        "type": "comment"
    },
    "464": {
        "file_id": 26,
        "content": "        gk = torch.zeros((B, T, C), device='cuda').contiguous()\n        gv = torch.zeros((B, T, C), device='cuda').contiguous()\n        if '32' in os.environ['RWKV_FLOAT_MODE']:\n            wkv_cuda.backward(B, T, C, w, u, k, v, gy.contiguous(), gw, gu, gk, gv)\n        else:\n            wkv_cuda.backward(B, T, C, w, u, k, v, gy.float().contiguous(), gw, gu, gk, gv)\n        gw = torch.sum(gw, dim=0)\n        gu = torch.sum(gu, dim=0)\n        if '32' in os.environ['RWKV_FLOAT_MODE']:\n            return (None, None, None, gw, gu, gk, gv)\n        elif os.environ['RWKV_FLOAT_MODE'] == 'fp16':\n            return (None, None, None, gw.half(), gu.half(), gk.half(), gv.half())\n        elif os.environ['RWKV_FLOAT_MODE'] == 'bf16':\n            return (None, None, None, gw.bfloat16(), gu.bfloat16(), gk.bfloat16(), gv.bfloat16())\ndef RUN_CUDA(B, T, C, w, u, k, v):\n    return WKV.apply(B, T, C, w.cuda(), u.cuda(), k.cuda(), v.cuda())\n########################################################################################################",
        "type": "code",
        "location": "/RWKV-v4/src/model.py:85-103"
    },
    "465": {
        "file_id": 26,
        "content": "The code defines a function that performs backward pass for the RWKV model on CUDA devices. It initializes gradients for weights and inputs, then applies the backward pass using the provided weights and input tensors. Depending on the RWKV_FLOAT_MODE environment variable, it returns gradients in different floating-point precisions or None if not running on a CUDA device. The RUN_CUDA function wraps this logic for convenience by moving model weights and inputs to CUDA devices before applying the backward pass.",
        "type": "comment"
    },
    "466": {
        "file_id": 26,
        "content": "# RWKV: RWKV Time-mix + RWKV Channel-mix\n########################################################################################################\ndef RWKV_Init(model, args):  # fancy initialization of all lin & emb layer in the model\n    print(\"\\n[--> first run, init model params (very slow for large models) <--]\")\n    print(\"[so you shall only do it for 1 single GPU and save the checkpt and load it when using multiple GPU]\\n\")\n    for mm in model.modules():\n        if \"RecursiveScriptModule\" in str(type(mm)):\n            if mm.original_name not in [\"Linear\"]:\n                continue\n            ww = None\n            for name, param in mm.named_parameters():\n                if name == \"weight\":\n                    ww = param\n        else:\n            m = mm\n            if not isinstance(m, (nn.Linear, nn.Embedding)):\n                continue\n            ww = m.weight\n        with torch.no_grad():\n            name = \"[unknown weight]\"\n            for name, parameter in model.named_parameters():  # find the name of the weight",
        "type": "code",
        "location": "/RWKV-v4/src/model.py:104-126"
    },
    "467": {
        "file_id": 26,
        "content": "This code initializes all linear and embedding layers in a model using fancy initialization. This is done by iterating through all modules of the model, skipping non-linear and non-embedding layers. It finds the weight parameters for these layers and performs some operations to initialize them, including finding their names. The code also provides some information about the process, such as it being slow for large models and needing to be run on a single GPU before loading onto others.",
        "type": "comment"
    },
    "468": {
        "file_id": 26,
        "content": "                if id(ww) == id(parameter):\n                    break\n            shape = ww.shape\n            gain = 1.0\n            scale = 1.0  # extra scale for gain\n            if isinstance(m, nn.Embedding):\n                gain = math.sqrt(max(shape[0], shape[1]))\n                if shape[0] == args.vocab_size and shape[1] == args.n_embd:  # token emb?\n                    scale = 1e-4\n                else:\n                    scale = 0\n            if isinstance(m, nn.Linear):\n                if shape[0] > shape[1]:\n                    gain = math.sqrt(shape[0] / shape[1])\n                if shape[0] == args.vocab_size and shape[1] == args.n_embd:  # final projection?\n                    scale = 0.5\n            if hasattr(m, \"scale_init\"):\n                scale = m.scale_init\n            # print(f\"{str(shape[0]).ljust(5)} {str(shape[1]).ljust(5)} {str(scale).ljust(4)} {name}\")\n            gain *= scale\n            if scale == -999:\n                nn.init.eye_(ww)\n            elif gain == 0:\n                # zero init is great for some RWKV matrices",
        "type": "code",
        "location": "/RWKV-v4/src/model.py:127-156"
    },
    "469": {
        "file_id": 26,
        "content": "This code is adjusting the weight matrix (`ww`) initializer of various neural network layers based on their shapes and types. It sets the gain and scale factors accordingly to optimize the model's performance. If `scale` is -999, it initializes with eye initialization. If `gain` is 0, it uses zero initialization. This process helps in setting up the weight matrices efficiently for RWKV models.",
        "type": "comment"
    },
    "470": {
        "file_id": 26,
        "content": "                nn.init.zeros_(ww)\n            elif gain > 0:\n                nn.init.orthogonal_(ww, gain=gain)\n            else:\n                nn.init.normal_(ww, mean=0.0, std=-scale)\nclass RWKV_TimeMix(torch.jit.ScriptModule):\n    def __init__(self, config, layer_id):\n        super().__init__()\n        self.layer_id = layer_id\n        self.ctx_len = config.ctx_len\n        self.n_embd = config.n_embd\n        attn_sz = config.n_embd\n        with torch.no_grad(): # fancy init\n            ratio_0_to_1 = (layer_id / (config.n_layer - 1)) # 0 to 1\n            ratio_1_to_almost0 = (1.0 - (layer_id / config.n_layer)) # 1 to ~0\n            # fancy time_decay\n            decay_speed = torch.ones(attn_sz)\n            for h in range(attn_sz):\n                decay_speed[h] = -5 + 8 * (h / (attn_sz-1)) ** (0.7 + 1.3 * ratio_0_to_1)\n            self.time_decay = nn.Parameter(decay_speed)\n            # print(layer_id, self.time_decay.flatten()[:3].cpu().numpy(), '...', self.time_decay.flatten()[-3:].cpu().numpy())\n            # fancy time_first",
        "type": "code",
        "location": "/RWKV-v4/src/model.py:157-184"
    },
    "471": {
        "file_id": 26,
        "content": "This code is initializing a layer of the RWKV_TimeMix model with fancy initialization for time decay parameter. It calculates the time decay speed based on the current layer and attenuation size, and assigns it to the `self.time_decay` parameter in the class.",
        "type": "comment"
    },
    "472": {
        "file_id": 26,
        "content": "            zigzag = (torch.tensor([(i+1)%3 - 1 for i in range(attn_sz)]) * 0.5)\n            self.time_first = nn.Parameter(torch.ones(attn_sz) * math.log(0.3) + zigzag)\n            # fancy time_mix\n            x = torch.ones(1, 1, config.n_embd)\n            for i in range(config.n_embd):\n                x[0, 0, i] = i / config.n_embd\n            self.time_mix_k = nn.Parameter(torch.pow(x, ratio_1_to_almost0))\n            self.time_mix_v = nn.Parameter(torch.pow(x, ratio_1_to_almost0) + 0.3 * ratio_0_to_1)\n            self.time_mix_r = nn.Parameter(torch.pow(x, 0.5 * ratio_1_to_almost0))\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        self.key = nn.Linear(config.n_embd, attn_sz, bias=False)\n        self.value = nn.Linear(config.n_embd, attn_sz, bias=False)\n        self.receptance = nn.Linear(config.n_embd, attn_sz, bias=False)\n        self.output = nn.Linear(attn_sz, config.n_embd, bias=False)\n        self.key.scale_init = 0\n        self.receptance.scale_init = 0\n        self.output.scale_init = 0",
        "type": "code",
        "location": "/RWKV-v4/src/model.py:185-206"
    },
    "473": {
        "file_id": 26,
        "content": "The code above initializes various layers for an attention mechanism in a transformer model. It defines parameters for time-based mixing, shifting, and linear transformations for keys, values, and output. The key, value, and output layers are initialized with zero scaling.",
        "type": "comment"
    },
    "474": {
        "file_id": 26,
        "content": "    @torch.jit.script_method\n    def jit_func(self, x):\n        # Mix x with the previous timestep to produce xk, xv, xr\n        xx = self.time_shift(x)\n        xk = x * self.time_mix_k + xx * (1 - self.time_mix_k)\n        xv = x * self.time_mix_v + xx * (1 - self.time_mix_v)\n        xr = x * self.time_mix_r + xx * (1 - self.time_mix_r)\n        # Use xk, xv, xr to produce k, v, r\n        k = self.key(xk)\n        v = self.value(xv)\n        r = self.receptance(xr)\n        sr = torch.sigmoid(r)\n        return sr, k, v\n    def forward(self, x):\n        B, T, C = x.size() # x = (Batch,Time,Channel)\n        sr, k, v = self.jit_func(x)\n        rwkv = sr * RUN_CUDA(B, T, C, self.time_decay, self.time_first, k, v)\n        rwkv = self.output(rwkv)\n        return rwkv\nclass RWKV_ChannelMix(torch.jit.ScriptModule):\n    def __init__(self, config, layer_id):\n        super().__init__()\n        self.layer_id = layer_id\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        with torch.no_grad(): # fancy init of time_mix",
        "type": "code",
        "location": "/RWKV-v4/src/model.py:208-242"
    },
    "475": {
        "file_id": 26,
        "content": "The code defines a model that performs channel-wise mixing and applies a time shift. The jit_func method takes an input tensor x, mixes it with the previous timestep to produce xk, xv, xr, and then calculates k, v, r using these mixed tensors. The forward method takes an input tensor x, calls the jit_func to obtain sr, k, v, applies a time decay, and returns the output from an output layer. RWKV_ChannelMix is a ScriptModule class that initializes the time shift and uses fancy initialization for time_mix.",
        "type": "comment"
    },
    "476": {
        "file_id": 26,
        "content": "            ratio_1_to_almost0 = (1.0 - (layer_id / config.n_layer)) # 1 to ~0\n            x = torch.ones(1, 1, config.n_embd)\n            for i in range(config.n_embd):\n                x[0, 0, i] = i / config.n_embd\n            self.time_mix_k = nn.Parameter(torch.pow(x, ratio_1_to_almost0))\n            self.time_mix_r = nn.Parameter(torch.pow(x, ratio_1_to_almost0))\n        hidden_sz = 4 * config.n_embd\n        self.key = nn.Linear(config.n_embd, hidden_sz, bias=False)\n        self.receptance = nn.Linear(config.n_embd, config.n_embd, bias=False)\n        self.value = nn.Linear(hidden_sz, config.n_embd, bias=False)\n        self.value.scale_init = 0\n        self.receptance.scale_init = 0\n    @torch.jit.script_method\n    def forward(self, x):\n        xx = self.time_shift(x)\n        xk = x * self.time_mix_k + xx * (1 - self.time_mix_k)\n        xr = x * self.time_mix_r + xx * (1 - self.time_mix_r)\n        k = self.key(xk)\n        k = torch.square(torch.relu(k))\n        kv = self.value(k)\n        rkv = torch.sigmoid(self.receptance(xr)) * kv",
        "type": "code",
        "location": "/RWKV-v4/src/model.py:243-270"
    },
    "477": {
        "file_id": 26,
        "content": "Code snippet initializes two parameters for time-mixing, sets hidden size and defines linear layers for key, receptance, and value in a transformer model. The forward method applies time-shifting, mixing, passing through key and value layers, and calculates the final output using sigmoid activation and multiplication.",
        "type": "comment"
    },
    "478": {
        "file_id": 26,
        "content": "        return rkv\n########################################################################################################\n# The GPT Model with our blocks\n########################################################################################################\nclass GPTConfig:\n    def __init__(self, vocab_size, ctx_len, **kwargs):\n        self.vocab_size = vocab_size\n        self.ctx_len = ctx_len\n        for k, v in kwargs.items():\n            setattr(self, k, v)\nclass Block(nn.Module):\n    def __init__(self, config, layer_id):\n        super().__init__()\n        self.config = config\n        self.layer_id = layer_id\n        self.ln1 = nn.LayerNorm(config.n_embd)\n        self.ln2 = nn.LayerNorm(config.n_embd)\n        if self.layer_id == 0:\n            self.ln0 = nn.LayerNorm(config.n_embd)\n        if self.layer_id == 0 and self.config.model_type == 'RWKV-ffnPre':\n            self.ffnPre = RWKV_ChannelMix(config, 0)\n        else:\n            self.att = RWKV_TimeMix(config, layer_id)\n        self.ffn = RWKV_ChannelMix(config, layer_id)",
        "type": "code",
        "location": "/RWKV-v4/src/model.py:271-303"
    },
    "479": {
        "file_id": 26,
        "content": "The code defines a GPT model with customizable blocks and config parameters. The GPTConfig class holds the vocabulary size, context length, and additional keyword-value pairs. The Block class is a module for these customizable blocks, using layer normalization, attention, and feed-forward layers, depending on the block type and position.",
        "type": "comment"
    },
    "480": {
        "file_id": 26,
        "content": "    def forward(self, x):\n        if self.layer_id == 0:\n            x = self.ln0(x)        \n        if self.layer_id == 0 and self.config.model_type == 'RWKV-ffnPre':\n            x = x + self.ffnPre(self.ln1(x))  # better in some cases\n        else:\n            x = x + self.att(self.ln1(x))\n        x = x + self.ffn(self.ln2(x))\n        return x\nclass GPT(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.step = 0\n        self.config = config\n        self.emb = nn.Embedding(config.vocab_size, config.n_embd)\n        self.blocks = nn.Sequential(*[Block(config, i)\n                                    for i in range(config.n_layer)])\n        self.ln_out = nn.LayerNorm(config.n_embd)\n        self.head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n        if RWKV_HEAD_QK_DIM > 0:\n            self.head_q = nn.Linear(config.n_embd, RWKV_HEAD_QK_DIM, bias=False)\n            self.head_q.scale_init = 0\n            self.head_k = nn.Linear(config.n_embd, RWKV_HEAD_QK_DIM, bias=False)",
        "type": "code",
        "location": "/RWKV-v4/src/model.py:305-333"
    },
    "481": {
        "file_id": 26,
        "content": "This code defines a GPT model class with layer normalization, embedding, and multiple blocks. The forward function performs feed-forward and attention mechanisms, and the __init__ function initializes the model parameters based on the given configuration.",
        "type": "comment"
    },
    "482": {
        "file_id": 26,
        "content": "            self.head_k.scale_init = 0.1\n            self.register_buffer(\"copy_mask\", torch.tril(\n                torch.ones(config.ctx_len, config.ctx_len)))\n        self.ctx_len = config.ctx_len\n        try:\n            if os.environ['RWKV_LOAD_MODEL'] == str(False):\n                RWKV_Init(self, config) \n        except:\n            pass\n        logger.info(\"number of parameters: %e\", sum(p.numel()\n                    for p in self.parameters()))\n    def get_ctx_len(self):\n        return self.ctx_len\n    def _init_weights(self, module):\n        if isinstance(module, (nn.Linear)):\n            module.weight.data.normal_(mean=0.0, std=0.01)\n        if isinstance(module, (nn.Embedding)):\n            module.weight.data.normal_(mean=0.0, std=1e-5)\n        if isinstance(module, nn.Linear) and module.bias is not None:\n            module.bias.data.zero_()\n    def configure_optimizers(self, train_config):\n        no_decay = set()\n        for mn, m in self.named_modules():  # here we disable weight_decay\n            for pn, p in m.named_parameters():",
        "type": "code",
        "location": "/RWKV-v4/src/model.py:334-364"
    },
    "483": {
        "file_id": 26,
        "content": "This code initializes the model, sets parameters such as head_k scale and copy mask, checks if the model should be loaded, and logs the number of parameters. It also defines methods for getting ctx_len, initializing weights with specific values, and configuring optimizers.",
        "type": "comment"
    },
    "484": {
        "file_id": 26,
        "content": "                fpn = '%s.%s' % (mn, pn) if mn else pn  # full param name\n                no_decay.add(fpn)\n        param_dict = {pn: p for pn, p in self.named_parameters()}\n        optim_groups = [\n            {\"params\": [param_dict[pn]\n                        for pn in sorted(list(no_decay))], \"weight_decay\": 0.0},\n        ]\n        try:\n            optimizer = FusedAdam(optim_groups, lr=train_config.learning_rate, betas=train_config.betas, eps=train_config.eps, bias_correction=True, adam_w_mode=False, weight_decay=0, amsgrad=False)\n        except:\n            print('\\n\\nDeepSpeed not found. Using torch optimizer instead (probably slower)\\n\\n')\n            optimizer = torch.optim.Adam(optim_groups, lr=train_config.learning_rate, betas=train_config.betas, eps=train_config.eps)\n        return optimizer\n    def forward(self, idx, targets=None):\n        idx = idx.to(self.emb.weight.device)\n        self.step += 1\n        B, T = idx.size()\n        assert T <= self.ctx_len, \"Cannot forward, because len(input) > model ctx_len.\"",
        "type": "code",
        "location": "/RWKV-v4/src/model.py:365-387"
    },
    "485": {
        "file_id": 26,
        "content": "This code initializes an optimizer for a model, either using DeepSpeed's FusedAdam if available or falling back to torch.optim.Adam. It defines the full param name and creates optimization groups based on whether or not weight decay should be applied. The forward function performs forward pass of the model and asserts that the input length is less than or equal to the context length.",
        "type": "comment"
    },
    "486": {
        "file_id": 26,
        "content": "        x = self.emb(idx)\n        x = self.blocks(x)\n        x = self.ln_out(x)\n        if RWKV_HEAD_QK_DIM > 0:\n            q = self.head_q(x)[:, :T, :]\n            k = self.head_k(x)[:, :T, :]\n            c = (q @ k.transpose(-2, -1)) * (1.0 / RWKV_HEAD_QK_DIM)\n            c = c.masked_fill(self.copy_mask[:T, :T] == 0, 0)\n            if '32' in os.environ['RWKV_FLOAT_MODE']:\n                c = c @ F.one_hot(idx, num_classes=self.config.vocab_size)\n            elif os.environ['RWKV_FLOAT_MODE'] == 'fp16':\n                c = c @ F.one_hot(idx, num_classes=self.config.vocab_size).half()\n            elif os.environ['RWKV_FLOAT_MODE'] == 'bf16':\n                c = c @ F.one_hot(idx, num_classes=self.config.vocab_size).bfloat16()\n            x = self.head(x) + c\n        else:\n            x = self.head(x)\n        loss = None\n        if targets is not None:\n            loss = F.cross_entropy(x.view(-1, x.size(-1)), targets.to(x.device).view(-1))\n        return L2Wrap.apply(loss, x)",
        "type": "code",
        "location": "/RWKV-v4/src/model.py:389-414"
    },
    "487": {
        "file_id": 26,
        "content": "This code calculates the attention scores using head layers, and then applies them to the output. If RWKV_HEAD_QK_DIM is greater than 0, it performs multi-head attention by computing the attention scores and scaling them based on the number of heads. Then, it adds a one-hot vector to the output depending on the RWKV_FLOAT_MODE environment variable, and finally calculates the cross-entropy loss between the output and targets (if provided), and returns the L2Wrap applied output and the loss.",
        "type": "comment"
    },
    "488": {
        "file_id": 27,
        "content": "/RWKV-v4/src/model_run.py",
        "type": "filepath"
    },
    "489": {
        "file_id": 27,
        "content": "The RWKV Language Model employs CUDA support, time-shifted operations, and forward passes for efficient execution. It trains a transformer model with head-multihead attention using RWKV-v4, organizes weights in namespaced structure, and performs layer normalization, feed-forward operations, and applies layers like LN and FFN.",
        "type": "summary"
    },
    "490": {
        "file_id": 27,
        "content": "########################################################################################################\n# The RWKV Language Model - https://github.com/BlinkDL/RWKV-LM\n########################################################################################################\nimport types\nimport copy\nimport torch\nimport math, os\nfrom torch.nn import functional as F\nimport torch.nn as nn\nRWKV_HEAD_QK_DIM = 0\nprint(f'\\nRWKV_HEAD_QK_DIM {RWKV_HEAD_QK_DIM}\\n')\nDEBUG_TIME = False   # True False - show trained time-coeffs\n########################################################################################################\n# CUDA Kernel\n########################################################################################################\nif os.environ['RWKV_RUN_DEVICE'] == 'cuda':\n    T_MAX = 1024 # increase this if your ctx_len is long [NOTE: TAKES LOTS OF VRAM!]\n    # it's possible to go beyond CUDA limitations if you slice the ctx and pass the hidden state in each slice\n    from torch.utils.cpp_extension import load",
        "type": "code",
        "location": "/RWKV-v4/src/model_run.py:1-25"
    },
    "491": {
        "file_id": 27,
        "content": "This code snippet is from the RWKV Language Model. It begins with importing necessary libraries and defines some constants like RWKV_HEAD_QK_DIM, DEBUG_TIME, and T_MAX. The code checks if the execution environment is CUDA and imports a CUDA kernel if it is. This language model is designed to perform natural language processing tasks with potential VRAM usage limitations.",
        "type": "comment"
    },
    "492": {
        "file_id": 27,
        "content": "    wkv_cuda = load(name=\"wkv\", sources=[\"cuda/wkv_op.cpp\", \"cuda/wkv_cuda.cu\"],\n                    verbose=True, extra_cuda_cflags=['-res-usage', '--maxrregcount 60', '--use_fast_math', '-O3', '-Xptxas -O3', f'-DTmax={T_MAX}'])\n    class WKV(torch.autograd.Function):\n        @staticmethod\n        def forward(ctx, B, T, C, w, u, k, v):\n            ctx.B = B\n            ctx.T = T\n            ctx.C = C\n            assert T <= T_MAX\n            assert B * C % min(C, 1024) == 0\n            if '32' in os.environ['RWKV_FLOAT_MODE']:\n                w = -torch.exp(w.contiguous())\n                u = u.contiguous()\n                k = k.contiguous()\n                v = v.contiguous()\n            else:\n                w = -torch.exp(w.float().contiguous())\n                u = u.float().contiguous()\n                k = k.float().contiguous()\n                v = v.float().contiguous()\n            ctx.save_for_backward(w, u, k, v)\n            y = torch.empty((B, T, C), device='cuda', memory_format=torch.contiguous_format)",
        "type": "code",
        "location": "/RWKV-v4/src/model_run.py:26-48"
    },
    "493": {
        "file_id": 27,
        "content": "This code initializes a WKV object, loads the model from CUDA, and handles float mode conversion. It asserts certain conditions, such as T being less than or equal to a maximum value, and B*C being divisible by min(C, 1024). The code also checks the environment variable 'RWKV_FLOAT_MODE' and converts the float types accordingly for compatibility. The model parameters are stored in the ctx object for backward propagation.",
        "type": "comment"
    },
    "494": {
        "file_id": 27,
        "content": "            wkv_cuda.forward(B, T, C, w, u, k, v, y)\n            if '32' in os.environ['RWKV_FLOAT_MODE']:\n                return y\n            elif os.environ['RWKV_FLOAT_MODE'] == 'fp16':\n                return y.half()\n            elif os.environ['RWKV_FLOAT_MODE'] == 'bf16':\n                return y.bfloat16()\n        @staticmethod\n        def backward(ctx, gy):\n            B = ctx.B\n            T = ctx.T\n            C = ctx.C\n            assert T <= T_MAX\n            assert B * C % min(C, 1024) == 0\n            w, u, k, v = ctx.saved_tensors\n            gw = torch.zeros((B, C), device='cuda').contiguous()\n            gu = torch.zeros((B, C), device='cuda').contiguous()\n            gk = torch.zeros((B, T, C), device='cuda').contiguous()\n            gv = torch.zeros((B, T, C), device='cuda').contiguous()\n            if '32' in os.environ['RWKV_FLOAT_MODE']:\n                wkv_cuda.backward(B, T, C, w, u, k, v, gy.contiguous(), gw, gu, gk, gv)\n            else:\n                wkv_cuda.backward(B, T, C, w, u, k, v, gy.float().contiguous(), gw, gu, gk, gv)",
        "type": "code",
        "location": "/RWKV-v4/src/model_run.py:49-72"
    },
    "495": {
        "file_id": 27,
        "content": "This code defines a function `forward` for a model that performs operations on input tensors B, T, C, w, u, k, and v. It also includes a backward function for gradient calculations using saved tensors. The `forward` function returns the output y, which is modified based on the environment variable RWKV_FLOAT_MODE. The backward function performs gradient calculations based on the input tensor gy and saves gradients in gw, gu, gk, and gv.",
        "type": "comment"
    },
    "496": {
        "file_id": 27,
        "content": "            gw = torch.sum(gw, dim=0)\n            gu = torch.sum(gu, dim=0)\n            if '32' in os.environ['RWKV_FLOAT_MODE']:\n                return (None, None, None, gw, gu, gk, gv)\n            elif os.environ['RWKV_FLOAT_MODE'] == 'fp16':\n                return (None, None, None, gw.half(), gu.half(), gk.half(), gv.half())\n            elif os.environ['RWKV_FLOAT_MODE'] == 'bf16':\n                return (None, None, None, gw.bfloat16(), gu.bfloat16(), gk.bfloat16(), gv.bfloat16())\n    def RUN_CUDA(B, T, C, w, u, k, v):\n        return WKV.apply(B, T, C, w.cuda(), u.cuda(), k.cuda(), v.cuda())\n############################################################################################################\nRWKV_CFG = types.SimpleNamespace()\nclass RWKV_ChannelMix(nn.Module):\n    def __init__(self, layer_id):\n        super().__init__()\n        self.layer_id = layer_id\n        self.time_shift = nn.ZeroPad2d((0,0,1,-1))\n        self.time_mix_k = nn.Parameter(torch.ones(1, 1, RWKV_CFG.n_embd))\n        self.time_mix_r = nn.Parameter(torch.ones(1, 1, RWKV_CFG.n_embd))",
        "type": "code",
        "location": "/RWKV-v4/src/model_run.py:73-96"
    },
    "497": {
        "file_id": 27,
        "content": "This code snippet is part of a model training and inference process. It defines a function `RUN_CUDA` for running the model on CUDA devices, and initializes a module `RWKV_ChannelMix`. The code also sets up various tensor operations such as summations, and environment variable checks for floating point precision modes. The module is part of the RWKV language model framework.",
        "type": "comment"
    },
    "498": {
        "file_id": 27,
        "content": "        hidden_sz = 4 * RWKV_CFG.n_embd\n        self.key = nn.Linear(RWKV_CFG.n_embd, hidden_sz, bias=False)\n        self.receptance = nn.Linear(RWKV_CFG.n_embd, RWKV_CFG.n_embd, bias=False)\n        self.value = nn.Linear(hidden_sz, RWKV_CFG.n_embd, bias=False)\n    def forward(self, x):\n        xx = self.time_shift(x)\n        xk = x * self.time_mix_k + xx * (1 - self.time_mix_k)\n        xr = x * self.time_mix_r + xx * (1 - self.time_mix_r)\n        k = self.key(xk)\n        k = torch.square(torch.relu(k))\n        kv = self.value(k)\n        rkv = torch.sigmoid(self.receptance(xr)) * kv\n        return rkv\nclass RWKV_TimeMix(nn.Module):\n    def __init__(self, layer_id):\n        super().__init__()\n        self.layer_id = layer_id\n        self.time_decay = nn.Parameter(torch.ones(RWKV_CFG.n_embd))\n        self.time_first = nn.Parameter(torch.ones(RWKV_CFG.n_embd) * math.log(0.3))\n        self.time_shift = nn.ZeroPad2d((0,0,1,-1))\n        self.time_mix_k = nn.Parameter(torch.ones(1,1,RWKV_CFG.n_embd))\n        self.time_mix_v = nn.Parameter(torch.ones(1,1,RWKV_CFG.n_embd))",
        "type": "code",
        "location": "/RWKV-v4/src/model_run.py:98-124"
    },
    "499": {
        "file_id": 27,
        "content": "Class \"RWKV_TimeMix\" initializes with layer id, and contains parameters for time decay, first position correction, shift operation, key mix, and value mix. The forward function applies time shifting, mixes with key and value mix parameters, applies square and relu operations on keys, multiplies by sigmoid-transformed values, and returns the result.",
        "type": "comment"
    }
}
{
    "summary": "The code defines a class \"MMapIndexedDataset\" with indexing methods and binary indexing functions for datasets, loading binary data from file paths using numpy's memmap. It supports setting document index and checking file existence.",
    "details": [
        {
            "comment": "This code is importing necessary libraries and defining functions for indexed datasets. It defines a class \"MMapIndexedDataset\" with an inner class \"Index\". The file includes utility functions like _warmup_mmap_file, print_rank_0, index_file_path, data_file_path, and code which handle reading and manipulating binary data from files. It also defines dtypes dictionary mapping numerical types to their respective codes.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4/src/binidx.py\":0-47",
            "content": "from lib2to3.pgen2 import token\nimport os\nimport torch\nimport numpy as np\nimport shutil\nimport struct\nfrom functools import lru_cache\nfrom itertools import accumulate\ndef print_rank_0(*message):\n    \"\"\"If distributed is initialized print only on rank 0.\"\"\"\n    if torch.distributed.is_initialized():\n        if torch.distributed.get_rank() == 0:\n            print(*message, flush=True)\n    else:\n        print(*message, flush=True)\ndef _warmup_mmap_file(path):\n    pass\n    # with open(path, \"rb\") as stream:\n    #     while stream.read(100 * 1024 * 1024):\n    #         pass\ndtypes = {\n    1: np.uint8,\n    2: np.int8,\n    3: np.int16,\n    4: np.int32,\n    5: np.int64,\n    6: float,\n    7: np.double,\n    8: np.uint16,\n}\ndef code(dtype):\n    for k in dtypes.keys():\n        if dtypes[k] == dtype:\n            return k\n    raise ValueError(dtype)\ndef index_file_path(prefix_path):\n    return prefix_path + \".idx\"\ndef data_file_path(prefix_path):\n    return prefix_path + \".bin\"\nclass MMapIndexedDataset(torch.utils.data.Dataset):\n    class Index(object):"
        },
        {
            "comment": "This code is initializing a class that reads an index file, checking if it matches the expected format, and storing relevant information such as dtype, dtype size, length, and document count. The skip_warmup parameter allows for optional warming up of the index file.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4/src/binidx.py\":48-71",
            "content": "        _HDR_MAGIC = b\"MMIDIDX\\x00\\x00\"\n        def __init__(self, path, skip_warmup=False):\n            with open(path, \"rb\") as stream:\n                magic_test = stream.read(9)\n                assert self._HDR_MAGIC == magic_test, (\n                    \"Index file doesn't match expected format. \"\n                    \"Make sure that --dataset-impl is configured properly.\"\n                )\n                # Little endian unsigned 64 Bit integer\n                version = struct.unpack(\"<Q\", stream.read(8))\n                assert (1,) == version\n                # Little endian unsigned 8 Bit integer\n                (dtype_code,) = struct.unpack(\"<B\", stream.read(1))\n                self._dtype = dtypes[dtype_code]\n                self._dtype_size = self._dtype().itemsize\n                self._len = struct.unpack(\"<Q\", stream.read(8))[0]\n                self._doc_count = struct.unpack(\"<Q\", stream.read(8))[0]\n                offset = stream.tell()\n            if not skip_warmup:\n                print_rank_0(\"    warming up index mmap file...\")"
        },
        {
            "comment": "The code is loading a binary file into memory using numpy's memmap. It reads sizes, pointers, and document index from the binary file, and finally closes the memory-mapped file in the destructor.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4/src/binidx.py\":72-97",
            "content": "                _warmup_mmap_file(path)\n            self._bin_buffer_mmap = np.memmap(path, mode=\"r\", order=\"C\")\n            self._bin_buffer = memoryview(self._bin_buffer_mmap)\n            print_rank_0(\"    reading sizes...\")\n            self._sizes = np.frombuffer(\n                self._bin_buffer, dtype=np.int32, count=self._len, offset=offset\n            )\n            print_rank_0(\"    reading pointers...\")\n            self._pointers = np.frombuffer(\n                self._bin_buffer,\n                dtype=np.int64,\n                count=self._len,\n                offset=offset + self._sizes.nbytes,\n            )\n            print_rank_0(\"    reading document index...\")\n            self._doc_idx = np.frombuffer(\n                self._bin_buffer,\n                dtype=np.int64,\n                count=self._doc_count,\n                offset=offset + self._sizes.nbytes + self._pointers.nbytes,\n            )\n        def __del__(self):\n            self._bin_buffer_mmap._mmap.close()\n            del self._bin_buffer_mmap"
        },
        {
            "comment": "This code defines a class for loading and accessing binary data from file paths. It has properties for dtype, sizes, and doc_idx, and provides getitem and len methods. The class also initializes itself with the given path and optionally skips warmup if specified. The __getstate__ and __setstate__ functions are used to serialize and deserialize the object's state, respectively.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4/src/binidx.py\":99-140",
            "content": "        @property\n        def dtype(self):\n            return self._dtype\n        @property\n        def sizes(self):\n            return self._sizes\n        @property\n        def doc_idx(self):\n            return self._doc_idx\n        @lru_cache(maxsize=8)\n        def __getitem__(self, i):\n            return self._pointers[i], self._sizes[i]\n        def __len__(self):\n            return self._len\n    def __init__(self, path, skip_warmup=False):\n        super().__init__()\n        self._path = None\n        self._index = None\n        self._bin_buffer = None\n        self._do_init(path, skip_warmup)\n    def __getstate__(self):\n        return self._path\n    def __setstate__(self, state):\n        self._do_init(state)\n    def _do_init(self, path, skip_warmup):\n        self._path = path\n        self._index = self.Index(index_file_path(self._path), skip_warmup)\n        if not skip_warmup:\n            print_rank_0(\"    warming up data mmap file...\")\n            _warmup_mmap_file(data_file_path(self._path))\n        print_rank_0(\"    creating numpy buffer of mmap...\")"
        },
        {
            "comment": "This code creates a memory view of a numpy buffer and closes the mmap on deletion. It also defines the length, getitem, and del methods for an indexed dataset. The __getitem__ method allows accessing elements based on integer or slice indices, but raises a ValueError if the slice is not contiguous.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4/src/binidx.py\":141-169",
            "content": "        self._bin_buffer_mmap = np.memmap(\n            data_file_path(self._path), mode=\"r\", order=\"C\"\n        )\n        print_rank_0(\"    creating memory view of numpy buffer...\")\n        self._bin_buffer = memoryview(self._bin_buffer_mmap)\n    def __del__(self):\n        self._bin_buffer_mmap._mmap.close()\n        del self._bin_buffer_mmap\n        del self._index\n    def __len__(self):\n        return len(self._index)\n    # @lru_cache(maxsize=8)\n    def __getitem__(self, idx):\n        if isinstance(idx, int):\n            ptr, size = self._index[idx]\n            np_array = np.frombuffer(\n                self._bin_buffer, dtype=self._index.dtype, count=size, offset=ptr\n            )\n            return np_array\n        elif isinstance(idx, slice):\n            start, stop, step = idx.indices(len(self))\n            if step != 1:\n                raise ValueError(\n                    \"Slices into indexed_dataset must be contiguous\")\n            ptr = self._index._pointers[start]\n            sizes = self._index._sizes[idx]"
        },
        {
            "comment": "This code defines two functions related to binary indexing for a dataset. The first function, \"binidx\", splits an array of sizes into offsets and creates a numpy array from the bin buffer with the specified total size and offset. The second function, \"get\", retrieves a single item from the dataset by using the provided index and optional offset and length parameters to extract a portion of the item. It also provides properties for accessing sizes and document indices.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4/src/binidx.py\":170-202",
            "content": "            offsets = list(accumulate(sizes))\n            total_size = sum(sizes)\n            np_array = np.frombuffer(\n                self._bin_buffer, dtype=self._index.dtype, count=total_size, offset=ptr\n            )\n            sents = np.split(np_array, offsets[:-1])\n            return sents\n    def get(self, idx, offset=0, length=None):\n        \"\"\"Retrieves a single item from the dataset with the option to only\n        return a portion of the item.\n        get(idx) is the same as [idx] but get() does not support slicing.\n        \"\"\"\n        ptr, size = self._index[idx]\n        if length is None:\n            length = size - offset\n        ptr += offset * np.dtype(self._index.dtype).itemsize\n        np_array = np.frombuffer(\n            self._bin_buffer, dtype=self._index.dtype, count=length, offset=ptr\n        )\n        return np_array\n    @property\n    def sizes(self):\n        return self._index.sizes\n    @property\n    def doc_idx(self):\n        return self._index.doc_idx\n    def get_doc_idx(self):\n        return self._index._doc_idx"
        },
        {
            "comment": "Function set_doc_idx sets the document index for the object, while supports_prefetch returns False. The exists function checks if both index and data files exist in the given path.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4/src/binidx.py\":204-215",
            "content": "    def set_doc_idx(self, doc_idx_):\n        self._index._doc_idx = doc_idx_\n    @property\n    def supports_prefetch(self):\n        return False\n    @staticmethod\n    def exists(path):\n        return os.path.exists(index_file_path(path)) and os.path.exists(\n            data_file_path(path)\n        )"
        }
    ]
}
{
    "summary": "This code initializes a transformer model for RWKV language implementation with time-shifted inputs, utilizing convolutions and attention mechanisms. It performs layer normalization, self-attention, feed-forward operations on input 'x' using layers from the 'w' object and returns results after applying block-specific weights and calculations for context-aware generation in RWKV-v3 model.",
    "details": [
        {
            "comment": "The code snippet is part of the RWKV language model implementation. It defines constants and a class for channel mixing operations within the model. The `RWKV_CFG` namespace holds various configuration values, and the `RWKV_ChannelMix` class represents a module with time-based channel mixing functionality using time shift, key, and query mixing parameters.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v3/src/model_run.py\":0-29",
            "content": "########################################################################################################\n# The RWKV Language Model - https://github.com/BlinkDL/RWKV-LM\n########################################################################################################\nimport types\nimport copy\nimport torch\nimport math\nfrom torch.nn import functional as F\nimport torch.nn as nn\nRWKV_K_CLAMP = 60\nRWKV_K_EPS = 1e-8\nRWKV_HEAD_QK_DIM = 256\nprint(f'\\nRWKV_K_CLAMP {RWKV_K_CLAMP} RWKV_K_EPS {RWKV_K_EPS} RWKV_HEAD_QK_DIM {RWKV_HEAD_QK_DIM}\\n')\nDEBUG_TIME = False   # True False - show trained time-coeffs\n############################################################################################################\nRWKV_CFG = types.SimpleNamespace()\nclass RWKV_ChannelMix(nn.Module):\n    def __init__(self, layer_id):\n        super().__init__()\n        self.layer_id = layer_id\n        self.time_shift = nn.ZeroPad2d((0,0,1,-1))\n        self.time_mix_k = nn.Parameter(torch.ones(1, 1, RWKV_CFG.n_embd))\n        self.time_mix_r = nn.Parameter(torch.ones(1, 1, RWKV_CFG.n_embd))"
        },
        {
            "comment": "RWKV-v3 model's forward function computes key-value pairs based on input tensor, using linear layers and element-wise operations. RWKV_TimeMix class initializes parameters for time-related operations in the model.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v3/src/model_run.py\":31-56",
            "content": "        hidden_sz = 4 * RWKV_CFG.n_embd\n        self.key = nn.Linear(RWKV_CFG.n_embd, hidden_sz, bias=False)\n        self.receptance = nn.Linear(RWKV_CFG.n_embd, RWKV_CFG.n_embd, bias=False)\n        self.value = nn.Linear(hidden_sz, RWKV_CFG.n_embd, bias=False)\n    def forward(self, x):\n        xx = self.time_shift(x)\n        xk = x * self.time_mix_k + xx * (1 - self.time_mix_k)\n        xr = x * self.time_mix_r + xx * (1 - self.time_mix_r)\n        k = self.key(xk)\n        k = torch.square(torch.relu(k))\n        kv = self.value(k)\n        rkv = torch.sigmoid(self.receptance(xr)) * kv\n        return rkv\nclass RWKV_TimeMix(nn.Module):\n    def __init__(self, layer_id):\n        super().__init__()\n        self.layer_id = layer_id\n        self.time_decay = nn.Parameter(torch.ones(RWKV_CFG.n_embd, 1))\n        self.time_curve = torch.tensor([-(RWKV_CFG.ctx_len - 2 - i) for i in range(RWKV_CFG.ctx_len-1)]).unsqueeze(0)\n        self.time_first = nn.Parameter(torch.ones(RWKV_CFG.n_embd, 1) * math.log(0.3))\n        self.time_shift = nn.ZeroPad2d((0,0,1,-1))"
        },
        {
            "comment": "This code initializes parameters for a transformer model and defines its forward pass. It uses time-shifted inputs, applies multiplication with learnable mixing factors, and feeds them into separate key, value, and receptance linear layers before clamping the keys, applying exponential function, and element-wise multiplying with values to obtain kv outputs.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v3/src/model_run.py\":57-84",
            "content": "        self.time_mix_k = nn.Parameter(torch.ones(1,1,RWKV_CFG.n_embd))\n        self.time_mix_v = nn.Parameter(torch.ones(1,1,RWKV_CFG.n_embd))\n        self.time_mix_r = nn.Parameter(torch.ones(1,1,RWKV_CFG.n_embd))\n        self.key = nn.Linear(RWKV_CFG.n_embd, RWKV_CFG.n_embd, bias=False)\n        self.value = nn.Linear(RWKV_CFG.n_embd, RWKV_CFG.n_embd, bias=False)\n        self.receptance = nn.Linear(RWKV_CFG.n_embd, RWKV_CFG.n_embd, bias=False)\n        self.output = nn.Linear(RWKV_CFG.n_embd, RWKV_CFG.n_embd, bias=False)\n    def forward(self, x):\n        B, T, C = x.size()\n        xx = self.time_shift(x)\n        xk = x * self.time_mix_k + xx * (1 - self.time_mix_k)\n        xv = x * self.time_mix_v + xx * (1 - self.time_mix_v)\n        xr = x * self.time_mix_r + xx * (1 - self.time_mix_r)\n        k = self.key(xk).transpose(-1, -2)\n        v = self.value(xv).transpose(-1, -2)\n        r = self.receptance(xr)\n        k = torch.clamp(k, max=RWKV_K_CLAMP)\n        k = torch.exp(k)\n        kv = k * v\n        sel"
        },
        {
            "comment": "Code snippet defines a `Block` class and its forward pass for a transformer model. The block consists of layer normalizations, an attention mechanism (`RWKV_TimeMix`), feed-forward network (`RWKV_ChannelMix`), and optional pre-feed-forward layer (`RWKV_ffnPre`) for the first block only. The time dimension is handled by `time_decay`, `time_curve`, and `time_first` variables, which are used to compute the weights for the convolutions. These weights are then applied to the input through 1D convolutions (`F.conv1d`) after padding the inputs with `nn.ZeroPad2d`. Finally, the output is passed through an activation function (`torch.sigmoid`) and a final layer normalization before being returned.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v3/src/model_run.py\":84-114",
            "content": "f.time_w = torch.cat([torch.exp(self.time_decay) * self.time_curve.to(self.time_decay.device), self.time_first], dim=-1)\n        w = torch.exp(self.time_w)\n        w = w[:,-T:].unsqueeze(1)\n        wkv = F.conv1d(nn.ZeroPad2d((T-1, 0, 0, 0))(kv), w, groups=C)\n        wk = F.conv1d(nn.ZeroPad2d((T-1, 0, 0, 0))(k), w, groups=C) + RWKV_K_EPS\n        rwkv = torch.sigmoid(r) * (wkv / wk).transpose(-1, -2)\n        rwkv = self.output(rwkv)\n        return rwkv\nclass Block(nn.Module):\n    def __init__(self, layer_id):\n        super().__init__()\n        self.layer_id = layer_id\n        self.ln1 = nn.LayerNorm(RWKV_CFG.n_embd)\n        self.ln2 = nn.LayerNorm(RWKV_CFG.n_embd)\n        if self.layer_id == 0:\n            self.ln0 = nn.LayerNorm(RWKV_CFG.n_embd)\n        if self.layer_id == 0 and RWKV_CFG.model_type == 'RWKV-ffnPre':\n            self.ffnPre = RWKV_ChannelMix(layer_id+1000)\n        else:\n            self.att = RWKV_TimeMix(layer_id)\n        self.ffn = RWKV_ChannelMix(layer_id)\n    def forward(self, x):\n        if self.layer_id == 0:"
        },
        {
            "comment": "The code snippet is a part of the RWKV-GPT class, which inherits from nn.Module in PyTorch. The class defines the architecture of the RWKV model, including embedding layer, layers with residual connections and normalization, and output layers. It takes inputs like MODEL_NAME, RUN_DEVICE, model_type, vocab_size, n_layer, n_embd, and ctx_len as parameters. The code block defines the initialization of the model components and applies layer normalization and linear transformations for the input and output layers.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v3/src/model_run.py\":115-145",
            "content": "            x = self.ln0(x)\n        if self.layer_id == 0 and RWKV_CFG.model_type == 'RWKV-ffnPre':\n            x = x + self.ffnPre(self.ln1(x))\n        else:\n            x = x + self.att(self.ln1(x))\n        x = x + self.ffn(self.ln2(x))\n        return x\nclass RWKV_GPT(nn.Module):\n    def __init__(self, MODEL_NAME, RUN_DEVICE, model_type, vocab_size, n_layer, n_embd, ctx_len):\n        global RWKV_CFG\n        super().__init__()\n        RWKV_CFG.RUN_DEVICE = RUN_DEVICE\n        RWKV_CFG.model_type = model_type\n        RWKV_CFG.vocab_size = vocab_size\n        RWKV_CFG.n_layer = n_layer\n        RWKV_CFG.n_embd = n_embd\n        RWKV_CFG.ctx_len = ctx_len\n        print('\\nloading RWKV-GPT', MODEL_NAME)\n        self.emb = nn.Embedding(vocab_size, n_embd)\n        self.blocks = nn.Sequential(*[Block(i) for i in range(n_layer)])\n        self.ln_out = nn.LayerNorm(n_embd)\n        self.head = nn.Linear(n_embd, vocab_size, bias=False)\n        if RWKV_HEAD_QK_DIM > 0:\n            self.head_q = nn.Linear(n_embd, RWKV_HEAD_QK_DIM, bias=False)"
        },
        {
            "comment": "This code initializes a model for the RWKV-v3 language model. It sets the head_q scale init and head_k's scale init, registers a copy mask, assigns ctx_len, loads state from a model file, and defines a forward function that performs forward propagation on input idx. If RWKV_HEAD_QK_DIM is greater than 0, it computes the context vector c using attention between query q and key k, masks self-attention with copy_mask, and adds c to head output before returning x.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v3/src/model_run.py\":146-176",
            "content": "            self.head_q.scale_init = 0\n            self.head_k = nn.Linear(n_embd, RWKV_HEAD_QK_DIM, bias=False)\n            self.head_k.scale_init = 0.1\n            self.register_buffer(\"copy_mask\", torch.tril(\n                torch.ones(ctx_len, ctx_len)))\n        self.ctx_len = ctx_len\n        self.eval()\n        self.load_state_dict(torch.load(MODEL_NAME + '.pth'))\n        self.eval()\n    def forward(self, idx):\n        B, T = idx.size()\n        assert T <= self.ctx_len, \"Cannot forward, because len(input) > model ctx_len.\"\n        x = self.emb(idx)\n        x = self.blocks(x)\n        x = self.ln_out(x)\n        if RWKV_HEAD_QK_DIM > 0:\n            q = self.head_q(x)[:, :T, :]\n            k = self.head_k(x)[:, :T, :]\n            c = (q @ k.transpose(-2, -1)) * (1.0 / RWKV_HEAD_QK_DIM)\n            c = c.masked_fill(self.copy_mask[:T, :T] == 0, 0)\n            c = c @ F.one_hot(idx, num_classes=RWKV_CFG.vocab_size).float()\n            x = self.head(x) + c\n        else:\n            x = self.head(x)        \n        return x"
        },
        {
            "comment": "The code defines a class called `RWKV_RNN` and initializes its attributes with provided parameters. It loads the model weights from the specified file, performing transformations on certain keys if required. Debugging options are also available for time-related variables.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v3/src/model_run.py\":178-206",
            "content": "############################################################################################################\nclass RWKV_RNN():\n    def __init__(self, MODEL_NAME, RUN_DEVICE, model_type, n_layer, n_embd, ctx_len):\n        self.RUN_DEVICE = RUN_DEVICE\n        self.model_type = model_type\n        self.n_layer = n_layer\n        self.n_embd = n_embd\n        self.ctx_len = ctx_len\n        self.w = types.SimpleNamespace()\n        w = torch.load(MODEL_NAME + '.pth',\n                       map_location=torch.device(RUN_DEVICE))\n        for x in w.keys():\n            if '.time_' in x:\n                w[x] = w[x].squeeze()\n            if '.time_decay' in x:\n                w[x] = torch.exp(-torch.exp(w[x]))\n            if '.time_first' in x:\n                w[x] = torch.exp(w[x])\n            if DEBUG_TIME and '.time_' in x:\n                print(x, w[x].squeeze().cpu().numpy())\n            xx = x.split('.')\n            here = self.w\n            for i in range(len(xx)):\n                if xx[i].isdigit():\n                    ii = int(xx[i])"
        },
        {
            "comment": "This code creates a hierarchical object structure using SimpleNamespace and dictionaries. It can be used to store and retrieve data in a nested manner. The clear method resets the stored data, while save and load methods allow copying the state of one instance to another.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v3/src/model_run.py\":207-237",
            "content": "                    if ii not in here:\n                        here[ii] = types.SimpleNamespace()\n                    here = here[ii]\n                else:\n                    if i == len(xx) - 1:\n                        setattr(here, xx[i], w[x])\n                    elif not hasattr(here, xx[i]):\n                        if xx[i+1].isdigit():\n                            setattr(here, xx[i], {})\n                        else:\n                            setattr(here, xx[i], types.SimpleNamespace())\n                    here = getattr(here, xx[i])\n        self.clear()\n    def clear(self):\n        self.xx = {}\n        self.aa = {}\n        self.bb = {}\n        self.hk = None\n    def save(self, target):\n        target.xx = copy.deepcopy(self.xx)\n        target.aa = copy.deepcopy(self.aa)\n        target.bb = copy.deepcopy(self.bb)\n        target.hk = copy.deepcopy(self.hk)\n    def load(self, target):\n        self.xx = copy.deepcopy(target.xx)\n        self.aa = copy.deepcopy(target.aa)\n        self.bb = copy.deepcopy(target.bb)"
        },
        {
            "comment": "The code defines three functions: `hk`, `LN`, and `FF`. The `hk` function copies the target's hk attribute. The `LN` function performs layer normalization on the input `xx` with provided weights `w`. The `FF` function implements a feed-forward layer, where it mixes `xx` with previous `name` values and applies sigmoid and relu functions before multiplying by weights. It also initializes `sa`, `aa`, and `bb` variables for subsequent SA operation.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v3/src/model_run.py\":238-263",
            "content": "        self.hk = copy.deepcopy(target.hk)\n    def LN(self, xx, w):\n        return F.layer_norm(xx, (self.n_embd,), weight=w.weight, bias=w.bias)\n    def FF(self, xx, w, name):\n        if name not in self.xx:\n            self.xx[name] = torch.zeros(self.n_embd, device=self.RUN_DEVICE)\n        xk = xx * w.time_mix_k + self.xx[name] * (1 - w.time_mix_k)\n        xr = xx * w.time_mix_r + self.xx[name] * (1 - w.time_mix_r)\n        self.xx[name] = xx\n        r = torch.sigmoid(w.receptance.weight @ xr)\n        k = torch.square(torch.relu(w.key.weight @ xk))\n        kv = w.value.weight @ k\n        return r * kv\n    def SA(self, xx, w, name):\n        if name not in self.xx:\n            self.xx[name] = torch.zeros(self.n_embd, device=self.RUN_DEVICE)\n            self.aa[name] = torch.zeros(self.n_embd, device=self.RUN_DEVICE)\n            self.bb[name] = torch.zeros(self.n_embd, device=self.RUN_DEVICE)\n        xk = xx * w.time_mix_k + self.xx[name] * (1 - w.time_mix_k)\n        xv = xx * w.time_mix_v + self.xx[name] * (1 - w.time_mix_v)"
        },
        {
            "comment": "This code performs a sequence of operations on the input 'x' using layers from the 'w' object. It applies layer normalization (LN), self-attention (SA), and feed-forward network (FF) for each block in the model. The result is then returned after applying weights and calculations specific to each block and layer.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v3/src/model_run.py\":264-293",
            "content": "        xr = xx * w.time_mix_r + self.xx[name] * (1 - w.time_mix_r)\n        self.xx[name] = xx\n        r = torch.sigmoid(w.receptance.weight @ xr)\n        k = torch.exp(torch.clamp(w.key.weight @ xk, max=RWKV_K_CLAMP))\n        v = w.value.weight @ xv\n        kv = k * v\n        a = self.aa[name] + w.time_first * kv\n        b = self.bb[name] + w.time_first * k\n        self.aa[name] = w.time_decay * self.aa[name] + kv\n        self.bb[name] = w.time_decay * self.bb[name] + k\n        rwkv = r * a / (b + RWKV_K_EPS)\n        return w.output.weight @ rwkv\n    def run(self, ctx):\n        w = self.w\n        x = w.emb.weight[ctx[-1]]\n        for i in range(self.n_layer):\n            if i == 0:\n                x = self.LN(x, w.blocks[i].ln0)\n            if i == 0 and self.model_type == 'RWKV-ffnPre':\n                x = x + self.FF(self.LN(x, w.blocks[i].ln1), w.blocks[i].ffnPre, f'ffnPre.{i}')\n            else:\n                x = x + self.SA(self.LN(x, w.blocks[i].ln1), w.blocks[i].att, f'att.{i}')\n            x = x + self.FF(self.LN(x, w.blocks[i].ln2), w.blocks[i].ffn, f'ffn.{i}')"
        },
        {
            "comment": "This code is part of the RWKV-v3 model and performs attention calculations for context-aware generation. It uses a linear layer (LN) to normalize input x with w.ln_out, calculates attention vectors q and x, and stores them in self.hk. If RWKV_HEAD_QK_DIM is greater than 0, it performs attention calculations; otherwise, it skips the process. The output x is converted to a list and returned.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v3/src/model_run.py\":295-318",
            "content": "        x = self.LN(x, w.ln_out)\n        if RWKV_HEAD_QK_DIM > 0:\n            if self.hk == None:\n                self.hk = (w.head_k.weight @ x).unsqueeze(0)\n            else:\n                self.hk = torch.cat(\n                    [self.hk, (w.head_k.weight @ x).unsqueeze(0)], dim=0)\n            if self.hk.shape[0] > self.ctx_len:\n                self.hk = self.hk[-self.ctx_len:, :]\n            q = w.head_q.weight @ x\n            x = w.head.weight @ x\n            x = x.cpu().numpy().tolist()\n            c = (self.hk @ q) / RWKV_HEAD_QK_DIM\n            for i in range(len(c)):\n                x[ctx[i]] += c[i]\n        else:\n            x = w.head.weight @ x\n            x = x.cpu().numpy().tolist()\n        return x"
        }
    ]
}
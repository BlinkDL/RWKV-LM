{
    "summary": "The code initializes and optimizes an RWKV Language Model in PyTorch, creates a model class with feed-forward network, applies deep learning processing techniques, checks if current layer is rescaling, adjusts input, and performs layer normalization/feed-forward operations before returning modified input and state.",
    "details": [
        {
            "comment": "This code is initializing the RWKV Language Model, which is implemented in PyTorch. It defines a module and function for optimizing the code using torchdynamo or torch jit depending on the environment variable RWKV_JIT_ON. The code also sets some variables like RWKV_HEAD_QK_DIM and DEBUG_TIME, which control certain aspects of the model's behavior.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4neo/src/model_run.py\":0-32",
            "content": "########################################################################################################\n# The RWKV Language Model - https://github.com/BlinkDL/RWKV-LM\n########################################################################################################\nimport types\nimport torch\nimport math, os, gc\nfrom torch.nn import functional as F\nimport torch.nn as nn\nfrom typing import List, Dict\nMyModule = nn.Module\ndef __nop(ob):\n    return ob\nMyFunction = __nop\n# # try torchdynamo\n# import torchdynamo\n# MyFunction = torchdynamo.optimize(os.environ[\"RWKV_RUN_BACKEND\"]) # !!!BUGGY!!! wrong output\n# try torch jit --> faster for fp32, slower for fp16 (why?)\nif os.environ[\"RWKV_JIT_ON\"] == \"1\":\n    MyModule = torch.jit.ScriptModule\n    MyFunction = torch.jit.script_method\nRWKV_HEAD_QK_DIM = 0\nprint(f'\\nRWKV_HEAD_QK_DIM {RWKV_HEAD_QK_DIM} RWKV_JIT_ON {os.environ[\"RWKV_JIT_ON\"]}\\n')\nDEBUG_TIME = False   # True False - show trained time-coeffs\nRWKV_RESCALE_LAYER = 6 # set x=x/2 every X layer\n############################################################################################################"
        },
        {
            "comment": "This code defines a class for the RWKV_RNN model, initializes its attributes based on provided arguments, loads and refines weights from a pre-trained model, adjusts certain layers' weights according to block ID, and handles loading and reshaping position embedding.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4neo/src/model_run.py\":34-60",
            "content": "class RWKV_RNN(MyModule):\n    def __init__(self, args):\n        super().__init__()\n        self.args = args\n        self.FLOAT_MODE = args.FLOAT_MODE\n        self.RUN_DEVICE = args.RUN_DEVICE\n        with torch.no_grad():\n            w = torch.load(args.MODEL_NAME + '.pth', map_location='cpu')\n            # refine weights and send to correct device\n            keys = list(w.keys())\n            if 'pos_emb_x' in keys:\n                w['pos_emb'] = (w['pos_emb_x'] + w['pos_emb_y']).reshape(args.ctx_len+1, -1)[:-1,:]\n            keys = list(w.keys())\n            print_need_newline = False\n            for x in keys:\n                block_id = 0\n                if 'blocks.' in x:\n                    block_id = int(x.split('.')[1])\n                if 'att.output.weight' in x:\n                    w[x] = w[x] / (2 ** int(block_id // RWKV_RESCALE_LAYER))\n                if 'ffn.value.weight' in x:\n                    w[x] = w[x] / (2 ** int(block_id // RWKV_RESCALE_LAYER))\n                if '.time_' in x:\n                    w[x] = w[x].squeeze()"
        },
        {
            "comment": "This code snippet is responsible for managing the data type and device of model parameters based on specified settings. It prints information about each parameter, including its name, data type, and device it's stored in. The DEBUG_TIME flag controls whether to print activation-time weights, while FLOAT_MODE determines the desired floating-point precision (fp32, fp16, or bf16). Parameters from specific groups are not modified unless they are in a specified group ('blocks.'). If RUN_DEVICE is 'cuda', parameters are moved to GPU if they're not the embedding layer weight.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4neo/src/model_run.py\":61-84",
            "content": "                    if DEBUG_TIME:\n                        print(x, w[x].numpy())\n                if '.time_decay' in x:\n                    w[x] = w[x].float()\n                    w[x] = -torch.exp(w[x])\n                elif '.time_first' in x:\n                    w[x] = w[x].float()\n                else:\n                    if self.FLOAT_MODE == \"fp32\":\n                        w[x] = w[x].float()\n                    elif self.FLOAT_MODE == \"bf16\":\n                        w[x] = w[x].bfloat16()\n                    elif self.FLOAT_MODE == \"fp16\":\n                        w[x] = w[x].half()\n                w[x].requires_grad = False\n                if args.RUN_DEVICE == 'cuda' and x != 'emb.weight':\n                    w[x] = w[x].cuda()\n                if ('blocks.' not in x) or ('blocks.0.' in x):\n                    if print_need_newline:\n                        print('\\n', end = '')\n                        print_need_newline = False\n                    print(x.ljust(40), str(w[x].dtype).replace('torch.', '').ljust(10), w[x].device)"
        },
        {
            "comment": "This code is organizing and storing weights from a dictionary 'w' into an object 'self.w'. It uses string manipulation to split keys into components, then iteratively creates nested namespaces or dictionaries within self.w according to the key structure. Finally, it sets attributes in each namespace/dictionary using setattr(). The code also ensures garbage collection and empties CUDA cache for optimization.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4neo/src/model_run.py\":85-113",
            "content": "                else:\n                    print_need_newline = True\n                    print('.', end = '', flush = True)\n        # store weights in self.w\n        keys = list(w.keys())\n        self.w = types.SimpleNamespace()\n        for x in keys:\n            xx = x.split('.')\n            here = self.w\n            for i in range(len(xx)):\n                if xx[i].isdigit():\n                    ii = int(xx[i])\n                    if ii not in here:\n                        here[ii] = types.SimpleNamespace()\n                    here = here[ii]\n                else:\n                    if i == len(xx) - 1:\n                        setattr(here, xx[i], w[x])\n                    elif not hasattr(here, xx[i]):\n                        if xx[i+1].isdigit():\n                            setattr(here, xx[i], {})\n                        else:\n                            setattr(here, xx[i], types.SimpleNamespace())\n                    here = getattr(here, xx[i])\n        self.eval()\n        gc.collect()\n        torch.cuda.empty_cache()"
        },
        {
            "comment": "This function, \"FF\", applies a feed-forward network (FFN) to the input tensor 'x' using state information from a previous iteration. It also accounts for different floating point types ('bf16', 'fp16') and performs element-wise operations with learnable weights. The resulting output is a product of the input, kernel, and weight matrices, with elements multiplied by sigmoid and squared ReLU activation functions respectively.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4neo/src/model_run.py\":115-139",
            "content": "    def LN(self, x, w):\n        return F.layer_norm(x, (self.args.n_embd,), weight=w.weight, bias=w.bias)\n    # state[] 0=ffn_xx 1=att_xx 2=att_aa 3=att_bb 4=att_pp\n    @MyFunction\n    def FF(self, x, state, i:int, time_mix_k, time_mix_r, kw, vw, rw):\n        if self.FLOAT_MODE == \"bf16\":\n            xk = x * time_mix_k + state[5*i+0].type(torch.bfloat16) * (1 - time_mix_k)\n            xr = x * time_mix_r + state[5*i+0].type(torch.bfloat16) * (1 - time_mix_r)\n            state[5*i+0] = x.float()\n        elif self.FLOAT_MODE == \"fp16\":\n            xk = x * time_mix_k + state[5*i+0].half() * (1 - time_mix_k)\n            xr = x * time_mix_r + state[5*i+0].half() * (1 - time_mix_r)\n            state[5*i+0] = x.float()            \n        else:\n            xk = x * time_mix_k + state[5*i+0] * (1 - time_mix_k)\n            xr = x * time_mix_r + state[5*i+0] * (1 - time_mix_r)\n            state[5*i+0] = x\n        r = torch.sigmoid(rw @ xr)\n        k = torch.square(torch.relu(kw @ xk))\n        kv = vw @ k\n        return r * kv"
        },
        {
            "comment": "This function calculates a weighted average of three inputs (x, xv, and xr) based on mixing factors and applies them to state[5*i+1]. Depending on FLOAT_MODE, it performs the calculation with different precision (bf16, fp16, or float32). The result is passed through a sigmoid function to obtain the final output r.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4neo/src/model_run.py\":141-159",
            "content": "    @MyFunction\n    def SA(self, x, state, i:int, time_mix_k, time_mix_v, time_mix_r, time_first, time_decay, kw, vw, rw, ow):\n        if self.FLOAT_MODE == \"bf16\":\n            xk = x * time_mix_k + state[5*i+1].type(torch.bfloat16) * (1 - time_mix_k)\n            xv = x * time_mix_v + state[5*i+1].type(torch.bfloat16) * (1 - time_mix_v)\n            xr = x * time_mix_r + state[5*i+1].type(torch.bfloat16) * (1 - time_mix_r)\n            state[5*i+1] = x.float()\n        elif self.FLOAT_MODE == \"fp16\":\n            xk = x * time_mix_k + state[5*i+1].half() * (1 - time_mix_k)\n            xv = x * time_mix_v + state[5*i+1].half() * (1 - time_mix_v)\n            xr = x * time_mix_r + state[5*i+1].half() * (1 - time_mix_r)\n            state[5*i+1] = x.float()            \n        else:\n            xk = x * time_mix_k + state[5*i+1] * (1 - time_mix_k)\n            xv = x * time_mix_v + state[5*i+1] * (1 - time_mix_v)\n            xr = x * time_mix_r + state[5*i+1] * (1 - time_mix_r)\n            state[5*i+1] = x\n        r = torch.sigmoid(rw @ xr)"
        },
        {
            "comment": "This code is performing a matrix multiplication operation and then applying exponential functions and maximum operations on the result. It also checks the FLOAT_MODE to handle different data types and returns the output of the operation.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4neo/src/model_run.py\":160-199",
            "content": "        k = kw @ xk\n        v = vw @ xv\n        if '16' in self.FLOAT_MODE:\n            kk = k.float()\n            vv = v.float()\n        else:\n            kk = k\n            vv = v\n        aa = state[5*i+2]\n        bb = state[5*i+3]\n        pp = state[5*i+4]\n        ww = time_first + kk\n        p = torch.maximum(pp, ww)\n        e1 = torch.exp(pp - p)\n        e2 = torch.exp(ww - p)\n        a = e1 * aa + e2 * vv\n        b = e1 * bb + e2\n        ww = pp + time_decay\n        p = torch.maximum(ww, kk)\n        e1 = torch.exp(ww - p)\n        e2 = torch.exp(kk - p)\n        state[5*i+2] = e1 * aa + e2 * vv\n        state[5*i+3] = e1 * bb + e2\n        state[5*i+4] = p\n        if self.FLOAT_MODE == \"bf16\":\n            wkv = (a / b).type(torch.bfloat16)\n        elif self.FLOAT_MODE == \"fp16\":\n            wkv = (a / b).half()\n        else:\n            wkv = a / b\n        return ow @ (r * wkv)\n    def forward(self, ctx, state, preprocess_only = False):\n        with torch.no_grad():\n            w = self.w\n            args = self.args\n            x = w.emb.weight[ctx[-1]]"
        },
        {
            "comment": "This code segment is responsible for handling the input data and processing it through a sequence of layers in a deep learning model. The RUN_DEVICE variable determines whether the computation should be done on CPU or GPU. Positional embedding is added to the input, and initial state values are set if necessary. Finally, the input goes through multiple layers, including attention and feed-forward networks, with appropriate time mixing and normalization.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4neo/src/model_run.py\":200-225",
            "content": "            if self.RUN_DEVICE == 'cuda':\n                x = x.cuda()\n            try:\n                pos_emb = w.pos_emb[len(ctx)-1]\n                x = x + pos_emb\n            except:\n                pass             \n            if state == None:\n                state = torch.zeros(args.n_layer * 5, args.n_embd, device=self.RUN_DEVICE)\n                for i in range(args.n_layer):\n                    state[5*i+4] -= 1e30\n            for i in range(args.n_layer):\n                if i == 0:\n                    x = self.LN(x, w.blocks[i].ln0)\n                ww = w.blocks[i].att\n                x = x + self.SA(self.LN(x, w.blocks[i].ln1), state, i, \n                    ww.time_mix_k, ww.time_mix_v, ww.time_mix_r, ww.time_first, ww.time_decay, \n                    ww.key.weight, ww.value.weight, ww.receptance.weight, ww.output.weight)\n                ww = w.blocks[i].ffn\n                x = x + self.FF(self.LN(x, w.blocks[i].ln2), state, i, \n                    ww.time_mix_k, ww.time_mix_r, \n                    ww.key.weight, ww.value.weight, ww.receptance.weight)"
        },
        {
            "comment": "This code segment checks if the current layer is a rescaling layer and adjusts the input accordingly. If preprocessing only is enabled, it returns the state; otherwise, it applies layer normalization and feed-forward operations before returning the modified input and state.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4neo/src/model_run.py\":227-236",
            "content": "                if (i+1) % RWKV_RESCALE_LAYER == 0:\n                    x = x / 2\n            if preprocess_only:\n                return state\n            x = self.LN(x, w.ln_out)\n            x = w.head.weight @ x\n            return x.float(), state"
        }
    ]
}
{
    "summary": "This C++ code implements forward and backward neural network operations using PyTorch tensors, optimized for CUDA execution. It includes functions for BFloat16 data type, with Python module \"wkv5\" for forward and backward operations.",
    "details": [
        {
            "comment": "This code is a C++ implementation of forward and backward passes for an unknown neural network operation. It includes functions `cuda_forward` and `cuda_backward`, which are called by the corresponding `forward` and `backward` wrapper functions. The wrapper functions handle memory allocation, type conversion, and data pointers for PyTorch tensors. The code uses BFloat16 as the floating-point data type and is optimized for CUDA execution.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4neo/cuda/wkv5_op.cpp\":0-11",
            "content": "#include <torch/extension.h>\n#include \"ATen/ATen.h\"\ntypedef at::BFloat16 bf16;\nvoid cuda_forward(int B, int T, int C, int H, bf16 *r, bf16 *k, bf16 *v, float *w, bf16 *u, bf16 *y);\nvoid cuda_backward(int B, int T, int C, int H, bf16 *r, bf16 *k, bf16 *v, float *w, float *ww, bf16 *u, bf16 *gy, bf16 *gr, bf16 *gk, bf16 *gv, bf16 *gw, bf16 *gu);\nvoid forward(int64_t B, int64_t T, int64_t C, int64_t H, torch::Tensor &r, torch::Tensor &k, torch::Tensor &v, torch::Tensor &w, torch::Tensor &u, torch::Tensor &y) {\n    cuda_forward(B, T, C, H, r.data_ptr<bf16>(), k.data_ptr<bf16>(), v.data_ptr<bf16>(), w.data_ptr<float>(), u.data_ptr<bf16>(), y.data_ptr<bf16>());\n}\nvoid backward(int64_t B, int64_t T, int64_t C, int64_t H, torch::Tensor &r, torch::Tensor &k, torch::Tensor &v, torch::Tensor &w, torch::Tensor &ww, torch::Tensor &u, torch::Tensor &gy, torch::Tensor &gr, torch::Tensor &gk, torch::Tensor &gv, torch::Tensor &gw, torch::Tensor &gu) {\n    cuda_backward(B, T, C, H, r.data_ptr<bf16>(), k.data_ptr"
        },
        {
            "comment": "This code defines a Python module for the \"wkv5\" function, which includes forward and backward operations. The variables declared represent different data pointers used in these operations.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4neo/cuda/wkv5_op.cpp\":11-21",
            "content": "<bf16>(), v.data_ptr<bf16>(), w.data_ptr<float>(), ww.data_ptr<float>(), u.data_ptr<bf16>(), gy.data_ptr<bf16>(), gr.data_ptr<bf16>(), gk.data_ptr<bf16>(), gv.data_ptr<bf16>(), gw.data_ptr<bf16>(), gu.data_ptr<bf16>());\n}\nPYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {\n    m.def(\"forward\", &forward, \"wkv5 forward\");\n    m.def(\"backward\", &backward, \"wkv5 backward\");\n}\nTORCH_LIBRARY(wkv5, m) {\n    m.def(\"forward\", forward);\n    m.def(\"backward\", backward);\n}"
        }
    ]
}
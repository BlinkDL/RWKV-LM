{
    "summary": "This code trains an RWKV language model with PyTorch Lightning, supports customizable training parameters, fine-tunes on enwik8 data, and saves models every 5 epochs using 'argparse' for command line arguments. It includes essential setup tasks like version assertions and learning rate schedule configuration.",
    "details": [
        {
            "comment": "This code is for training an RWKV language model using PyTorch Lightning framework. It includes basic configuration, argument parsing, and example usage for training a simple L12-D768 RWKV model on dummy data. The user can specify various parameters like load_model, wandb, proj_dir, data_file, data_type, vocab_size, ctx_len, epoch_steps, epoch_count, epoch_begin, epoch_save, micro_bsz, n_layer, n_embd, pre_ffn, and head_qk.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4neo/train.py\":0-22",
            "content": "########################################################################################################\n# The RWKV Language Model - https://github.com/BlinkDL/RWKV-LM\n########################################################################################################\nimport logging\nlogging.basicConfig(level=logging.INFO)\nif __name__ == \"__main__\":\n    from argparse import ArgumentParser\n    from pytorch_lightning import Trainer\n    from pytorch_lightning.utilities import rank_zero_info, rank_zero_only\n    import pytorch_lightning as pl\n    rank_zero_info(\"########## work in progress ##########\")\n    ########################################################################################################\n    #\n    # example: train a simple L12-D768 RWKV on dummy data\n    #\n    # python train.py --load_model \"\" --wandb \"\" --proj_dir \"out\" \\\n    # --data_file \"\" --data_type \"dummy\" --vocab_size 0 \\\n    # --ctx_len 128 --epoch_steps 1000 --epoch_count 20 --epoch_begin 0 --epoch_save 10 \\\n    # --micro_bsz 16 --n_layer 12 --n_embd 768 --pre_ffn 0 --head_qk 0 \\"
        },
        {
            "comment": "Train a simple L6-D512 RWKV from scratch on enwik8, fine-tune RWKV 1.5B using 8xA100 40G = 1.76it/s = 115k token/s, VRAM 37477M",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4neo/train.py\":23-38",
            "content": "    # --lr_init 6e-4 --lr_final 1e-5 --warmup_steps 0 --beta1 0.9 --beta2 0.99 --adam_eps 1e-8 \\\n    # --accelerator gpu --devices 1 --precision bf16 --strategy ddp_find_unused_parameters_false --grad_cp 0\n    # example: train a simple L6-D512 RWKV from scratch on enwik8\n    #\n    # python train.py --load_model \"\" --wandb \"\" --proj_dir \"out\" \\\n    # --data_file \"../data/enwik8\" --data_type \"utf-8\" --vocab_size 0 \\\n    # --ctx_len 512 --epoch_steps 5000 --epoch_count 500 --epoch_begin 0 --epoch_save 5 \\\n    # --micro_bsz 12 --n_layer 6 --n_embd 512 --pre_ffn 0 --head_qk 0 \\\n    # --lr_init 8e-4 --lr_final 1e-5 --warmup_steps 0 --beta1 0.9 --beta2 0.99 --adam_eps 1e-8 \\\n    # --accelerator gpu --devices 1 --precision bf16 --strategy ddp_find_unused_parameters_false --grad_cp 0\n    # example: fine-tune RWKV 1.5B using 8xA100 40G = 1.76it/s = 115k token/s, VRAM 37477M\n    #\n    # python train.py --load_model \"/fsx/BlinkDL/CODE/FP16/out_1b2/all-8040.pth\" --wandb \"\" --proj_dir \"out\" \\\n    # --data_file \"../data/train.npy\" --data_type \"numpy\" --vocab_size 50277 \\"
        },
        {
            "comment": "This code configures a fine-tuning process for RWKV using 8 GPUs with BF16 precision, and saves models every 5 epochs. The command line arguments specify the model path, W&B project directory, training data file, vocabulary size, and various hyperparameters like batch size, layers, embedding dimensions, learning rate, etc. The parser is used to parse these command line arguments.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4neo/train.py\":39-53",
            "content": "    # --ctx_len 1024 --epoch_steps 1000 --epoch_count 1000 --epoch_begin 0 --epoch_save 5 \\\n    # --micro_bsz 8 --n_layer 24 --n_embd 2048 --pre_ffn 0 --head_qk 0 \\\n    # --lr_init 1e-5 --lr_final 1e-5 --warmup_steps 0 --beta1 0.9 --beta2 0.999 --adam_eps 1e-8 \\\n    # --accelerator gpu --devices 8 --precision bf16 --strategy deepspeed_stage_2 --grad_cp 0\n    # example: fine-tune RWKV 1.5B using 1 GPU fp16 (VRAM 16G) NOTE: fp16 might overflow\n    #\n    # python train.py --load_model \"/fsx/BlinkDL/CODE/FP16/out_1b2/all-8040.pth\" --wandb \"\" --proj_dir \"out\" \\\n    # --data_file \"../data/train.npy\" --data_type \"numpy\" --vocab_size 50277 \\\n    # --ctx_len 1024 --epoch_steps 200 --epoch_count 1000 --epoch_begin 0 --epoch_save 1 \\\n    # --micro_bsz 11 --n_layer 24 --n_embd 2048 --pre_ffn 0 --head_qk 0 \\\n    # --lr_init 1e-5 --lr_final 1e-5 --warmup_steps 0 --beta1 0.9 --beta2 0.999 --adam_eps 1e-8 \\\n    # --accelerator gpu --devices 1 --precision fp16 --strategy deepspeed_stage_2_offload --grad_cp 1\n    parser = ArgumentParser()"
        },
        {
            "comment": "This code is using the 'argparse' module to add command line arguments for specifying a model load path, Wandb project name, project directory, random seed, data file, data type, vocabulary size, context length, epoch steps, training epochs count, and epoch begin point. These arguments control how the program behaves during execution.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4neo/train.py\":55-68",
            "content": "    parser.add_argument(\"--load_model\", default=\"\", type=str)  # full path, with .pth\n    parser.add_argument(\"--wandb\", default=\"\", type=str)  # wandb project name. if \"\" then don't use wandb\n    parser.add_argument(\"--proj_dir\", default=\"out\", type=str)\n    parser.add_argument(\"--random_seed\", default=\"-1\", type=int)\n    parser.add_argument(\"--data_file\", default=\"\", type=str)\n    parser.add_argument(\"--data_type\", default=\"utf-8\", type=str)\n    parser.add_argument(\"--vocab_size\", default=0, type=int)  # vocab_size = 0 means auto (for char-level LM and .txt data)\n    parser.add_argument(\"--ctx_len\", default=1024, type=int)\n    parser.add_argument(\"--epoch_steps\", default=1000, type=int)  # a mini \"epoch\" has [epoch_steps] steps\n    parser.add_argument(\"--epoch_count\", default=500, type=int)  # train for this many \"epochs\". will continue afterwards with lr = lr_final\n    parser.add_argument(\"--epoch_begin\", default=0, type=int)  # if you load a model trained for x \"epochs\", set epoch_begin = x\n "
        },
        {
            "comment": "This code snippet from \"RWKV-LM/RWKV-v4neo/train.py\" provides default values and types for various command line arguments used in model training. These parameters control aspects like epoch save frequency, batch size per GPU, model layers, embedding dimension, activation function settings, and learning rate configurations. The code also includes optional features like the \"headQK trick\", tiny attention dimensions, and layer placement.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4neo/train.py\":68-82",
            "content": "   parser.add_argument(\"--epoch_save\", default=5, type=int)  # save the model every [epoch_save] \"epochs\"\n    parser.add_argument(\"--micro_bsz\", default=12, type=int)  # micro batch size (batch size per GPU)\n    parser.add_argument(\"--n_layer\", default=6, type=int)\n    parser.add_argument(\"--n_embd\", default=512, type=int)\n    parser.add_argument(\"--dim_att\", default=0, type=int)\n    parser.add_argument(\"--dim_ffn\", default=0, type=int)\n    parser.add_argument(\"--pre_ffn\", default=0, type=int)  # replace first att layer by ffn (sometimes better)\n    parser.add_argument(\"--head_qk\", default=0, type=int)  # my headQK trick\n    parser.add_argument(\"--tiny_att_dim\", default=0, type=int)  # tiny attention dim\n    parser.add_argument(\"--tiny_att_layer\", default=-999, type=int)  # tiny attention @ which layer\n    parser.add_argument(\"--lr_init\", default=6e-4, type=float)  # 6e-4 for L12-D768, 4e-4 for L24-D1024, 3e-4 for L24-D2048\n    parser.add_argument(\"--lr_final\", default=1e-5, type=float)\n    parser.add_argument(\"--warmup_steps\", default=-1, type=int)  # try 50 if you load a model"
        },
        {
            "comment": "The code is using the 'argparse' module to add arguments for hyperparameters, such as beta1 and beta2 values for Adam optimizer, Adam epsilon, gradient checkpoint frequency, dropout rate, weight decay, special pile version and stage, text shift for special pile, and layerwise learning rate.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4neo/train.py\":83-95",
            "content": "    parser.add_argument(\"--beta1\", default=0.9, type=float)\n    parser.add_argument(\"--beta2\", default=0.99, type=float)  # use 0.999 when your model is close to convergence\n    parser.add_argument(\"--adam_eps\", default=1e-8, type=float)\n    parser.add_argument(\"--grad_cp\", default=0, type=int)  # gradient checkpt: saves VRAM, but slower\n    parser.add_argument(\"--dropout\", default=0, type=float) # try 0.01 / 0.02 / 0.05 / 0.1\n    parser.add_argument(\"--weight_decay\", default=0, type=float) # try 0.1 / 0.01 / 0.001\n    parser.add_argument(\"--weight_decay_final\", default=-1, type=float)\n    parser.add_argument(\"--my_pile_version\", default=1, type=int)  # my special pile version\n    parser.add_argument(\"--my_pile_stage\", default=0, type=int)  # my special pile mode\n    parser.add_argument(\"--my_pile_shift\", default=-1, type=int)  # my special pile mode - text shift\n    parser.add_argument(\"--my_pile_edecay\", default=0, type=int)\n    parser.add_argument(\"--layerwise_lr\", default=1, type=int)  # layerwise lr for faster convergence (but slower it/s)"
        },
        {
            "comment": "This code snippet contains various command line arguments used in a training process. It defines the default values and types for these arguments, such as --ds_bucket_mb, --cuda_cleanup, --my_img_version, etc. These options control different aspects of the model's behavior or performance during training. For instance, --my_sample_len specifies the length of samples to use while training, and --head_size_a sets the size of attention heads for the model. The code provides default values that should be sufficient for most cases but can be modified if needed.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4neo/train.py\":96-110",
            "content": "    parser.add_argument(\"--ds_bucket_mb\", default=200, type=int)  # deepspeed bucket size in MB. 200 seems enough\n    # parser.add_argument(\"--cuda_cleanup\", default=0, type=int)  # extra cuda cleanup (sometimes helpful)\n    parser.add_argument(\"--my_img_version\", default=0, type=str)\n    parser.add_argument(\"--my_img_size\", default=0, type=int)\n    parser.add_argument(\"--my_img_bit\", default=0, type=int)\n    parser.add_argument(\"--my_img_clip\", default='x', type=str)\n    parser.add_argument(\"--my_img_clip_scale\", default=1, type=float)\n    parser.add_argument(\"--my_img_l1_scale\", default=0, type=float)\n    parser.add_argument(\"--my_img_encoder\", default='x', type=str)\n    # parser.add_argument(\"--my_img_noise_scale\", default=0, type=float)\n    parser.add_argument(\"--my_sample_len\", default=0, type=int)\n    parser.add_argument(\"--my_ffn_shift\", default=1, type=int)\n    parser.add_argument(\"--my_att_shift\", default=1, type=int)\n    parser.add_argument(\"--head_size_a\", default=64, type=int) # can try larger values for larger models"
        },
        {
            "comment": "This code defines command-line arguments for a program using the 'argparse' module. The options include settings for model training (like head size, loading partial data, magic prime), as well as accelerator configuration in case of running on PyTorch Lightning (PL) with Python 2. No comments are needed as this is just defining command-line arguments.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4neo/train.py\":111-128",
            "content": "    parser.add_argument(\"--head_size_divisor\", default=8, type=int)\n    parser.add_argument(\"--my_pos_emb\", default=0, type=int)\n    parser.add_argument(\"--load_partial\", default=0, type=int)\n    parser.add_argument(\"--magic_prime\", default=0, type=int)\n    parser.add_argument(\"--my_qa_mask\", default=0, type=int)\n    parser.add_argument(\"--my_random_steps\", default=0, type=int)\n    parser.add_argument(\"--my_testing\", default='', type=str)\n    parser.add_argument(\"--my_exit\", default=99999999, type=int)\n    parser.add_argument(\"--my_exit_tokens\", default=0, type=int)\n    if pl.__version__[0]=='2':\n        parser.add_argument(\"--accelerator\", default=\"gpu\", type=str)\n        parser.add_argument(\"--strategy\", default=\"auto\", type=str)\n        parser.add_argument(\"--devices\", default=1, type=int)\n        parser.add_argument(\"--num_nodes\", default=1, type=int)\n        parser.add_argument(\"--precision\", default=\"fp16\", type=str)\n        parser.add_argument(\"--accumulate_grad_batches\", default=1, type=int)\n    else:"
        },
        {
            "comment": "This code snippet is importing necessary libraries and setting up global seed for multi-GPU sampling. It also configures print options, ignores certain warnings, and sets the timestamp for experiment name.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4neo/train.py\":129-152",
            "content": "        parser = Trainer.add_argparse_args(parser)\n    args = parser.parse_args()\n    ########################################################################################################\n    import os, warnings, math, datetime, sys, time\n    import numpy as np\n    import torch\n    from torch.utils.data import DataLoader\n    if \"deepspeed\" in args.strategy:\n        import deepspeed\n    from pytorch_lightning import seed_everything\n    if args.random_seed >= 0:\n        print(f\"########## WARNING: GLOBAL SEED {args.random_seed} THIS WILL AFFECT MULTIGPU SAMPLING ##########\\n\" * 3)\n        seed_everything(args.random_seed)\n    np.set_printoptions(precision=4, suppress=True, linewidth=200)\n    warnings.filterwarnings(\"ignore\", \".*Consider increasing the value of the `num_workers` argument*\")\n    warnings.filterwarnings(\"ignore\", \".*The progress bar already tracks a metric with the*\")\n    # os.environ[\"WDS_SHOW_SEED\"] = \"1\"\n    args.my_timestamp = datetime.datetime.today().strftime(\"%Y-%m-%d-%H-%M-%S\")\n    args.enable_checkpointing = False"
        },
        {
            "comment": "The code sets various arguments for model training, including disabling DDP sampler and logger, setting gradient clip value, and modifying batch size based on the number of nodes and devices. It also adjusts the dimensions of attention and feedforward layers if necessary, and customizes run name based on data type or vocabulary size, context length, layer count, and embedding dimension.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4neo/train.py\":153-177",
            "content": "    args.replace_sampler_ddp = False\n    args.logger = False\n    args.gradient_clip_val = 1.0\n    args.num_sanity_val_steps = 0\n    args.check_val_every_n_epoch = int(1e20)\n    args.log_every_n_steps = int(1e20)\n    args.max_epochs = -1  # continue forever\n    args.betas = (args.beta1, args.beta2)\n    args.real_bsz = int(args.num_nodes) * int(args.devices) * args.micro_bsz\n    os.environ[\"RWKV_T_MAX\"] = str(args.ctx_len)\n    os.environ[\"RWKV_MY_TESTING\"] = args.my_testing\n    os.environ[\"RWKV_HEAD_SIZE_A\"] = str(args.head_size_a)\n    if args.dim_att <= 0:\n        args.dim_att = args.n_embd\n    if args.dim_ffn <= 0:\n        if 'r3' in args.my_testing:\n            args.dim_ffn = int((args.n_embd * 3.5) // 32 * 32)\n        else:\n            args.dim_ffn = args.n_embd * 4\n    if args.data_type == \"wds_img\":\n        args.run_name = f\"v{args.my_img_version}-{args.my_img_size}-{args.my_img_bit}bit-{args.my_img_clip}x{args.my_img_clip_scale}\"\n        args.proj_dir = f\"{args.proj_dir}-{args.run_name}\"\n    else:\n        args.run_name = f\"{args.vocab_size} ctx{args.ctx_len} L{args.n_layer} D{args.n_embd}\""
        },
        {
            "comment": "This code checks if a directory exists, creates it if not, adjusts magic_prime and my_pile_shift values based on ctx_len, and sets my_pile_shift to 0 if it's negative.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4neo/train.py\":178-207",
            "content": "    if not os.path.exists(args.proj_dir):\n        os.makedirs(args.proj_dir)\n    if args.my_pile_stage > 0:\n        magic_prime_bak = args.magic_prime\n        if args.my_pile_version == 1:\n            if args.ctx_len == 1024:\n                args.magic_prime = 324331313\n            elif args.ctx_len == 2048:\n                args.magic_prime = 162165671\n            elif args.ctx_len == 4096:\n                args.magic_prime = 81082817\n            elif args.ctx_len == 8192:\n                args.magic_prime = 40541399\n        else:\n            if args.ctx_len == 1024:\n                args.magic_prime = 1670239709\n            elif args.ctx_len == 2048:\n                args.magic_prime = 835119767\n            elif args.ctx_len == 4096:\n                args.magic_prime = 417559889\n            elif args.ctx_len == 6144:\n                args.magic_prime = 278373239\n            elif args.ctx_len == 8192:\n                args.magic_prime = 208779911\n        if args.my_pile_shift < 0:\n            args.my_pile_shift = 0\n        if magic_prime_bak > 0:"
        },
        {
            "comment": "This code sets the epoch count based on magic_prime and my_qa_mask, determines epoch steps for batch size, asserts that their product equals 40320, and checks if my_pile_stage is 2 to find the latest saved model. If my_pile_stage >= 2, it lists all models in proj_dir, sorts them, sets max_p as last one, and my_pile_prev_p if there are more than one.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4neo/train.py\":208-232",
            "content": "            args.magic_prime = magic_prime_bak\n        if args.my_qa_mask == 2:\n            args.epoch_count = 2 * args.magic_prime // 40320\n        else:\n            args.epoch_count = args.magic_prime // 40320\n        args.epoch_steps = 40320 // args.real_bsz\n        assert args.epoch_steps * args.real_bsz == 40320\n        # if args.my_pile_stage == 2:\n        #     assert args.lr_final == args.lr_init\n        if args.my_pile_stage >= 2:  # find latest saved model\n            list_p = []\n            for p in os.listdir(args.proj_dir):\n                if p.startswith(\"rwkv\") and p.endswith(\".pth\"):\n                    p = ((p.split(\"-\"))[1].split(\".\"))[0]\n                    if p != \"final\":\n                        if p == \"init\":\n                            p = -1\n                        else:\n                            p = int(p)\n                        list_p += [p]\n            list_p.sort()\n            max_p = list_p[-1]\n            if len(list_p) > 1:\n                args.my_pile_prev_p = list_p[-2]  # in case max_p is corrupted"
        },
        {
            "comment": "If max_p is -1, the model will be loaded from rwkv-init.pth in args.proj_dir. Else, it will load from rwkv-{max_p}.pth in args.proj_dir. If warmup_steps is less than 0, set warmup_steps depending on my_pile_stage. Calculate samples_per_epoch and tokens_per_epoch based on epoch_steps and ctx_len respectively. Retrieve deepspeed version. Display rank_zero_info message with relevant information about the model, data, and project directory.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4neo/train.py\":233-257",
            "content": "            if max_p == -1:\n                args.load_model = f\"{args.proj_dir}/rwkv-init.pth\"\n            else:\n                args.load_model = f\"{args.proj_dir}/rwkv-{max_p}.pth\"\n                if args.warmup_steps < 0:\n                    if args.my_pile_stage == 2:\n                        args.warmup_steps = 10\n                    else:\n                        args.warmup_steps = 30\n            args.epoch_begin = max_p + 1\n    samples_per_epoch = args.epoch_steps * args.real_bsz\n    tokens_per_epoch = samples_per_epoch * args.ctx_len\n    try:\n        deepspeed_version = deepspeed.__version__\n    except:\n        deepspeed_version = None\n        pass\n    rank_zero_info(\n        f\"\"\"\n############################################################################\n#\n# RWKV-4 {args.precision.upper()} on {args.num_nodes}x{args.devices} {args.accelerator.upper()}, bsz {args.num_nodes}x{args.devices}x{args.micro_bsz}={args.real_bsz}, {args.strategy} {'with grad_cp' if args.grad_cp > 0 else ''}\n#\n# Data = {args.data_file} ({args.data_type}), ProjDir = {args.proj_dir}"
        },
        {
            "comment": "Code snippet defines variables for epochs, steps, samples, tokens, model layers, embedding size, context length, learning rate schedule, warmup steps, beta, and epsilon. It also mentions required Python libraries versions and their recommendations. The code asserts the data type and provides a note if either final or initial learning rate is zero, suggesting that it will use a linear learning rate schedule instead.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4neo/train.py\":258-279",
            "content": "#\n# Epoch = {args.epoch_begin} to {args.epoch_begin + args.epoch_count - 1} (will continue afterwards), save every {args.epoch_save} epoch\n#\n# Each \"epoch\" = {args.epoch_steps} steps, {samples_per_epoch} samples, {tokens_per_epoch} tokens\n#\n# Model = {args.n_layer} n_layer, {args.n_embd} n_embd, {args.ctx_len} ctx_len\n#\n# Adam = lr {args.lr_init} to {args.lr_final}, warmup {args.warmup_steps} steps, beta {args.betas}, eps {args.adam_eps}\n#\n# Found torch {torch.__version__}, recommend 1.13.1+cu117 or newer\n# Found deepspeed {deepspeed_version}, recommend 0.7.0 (faster than newer versions)\n# Found pytorch_lightning {pl.__version__}, recommend 1.9.5\n#\n############################################################################\n\"\"\"\n    )\n    rank_zero_info(str(vars(args)) + \"\\n\")\n    assert args.data_type in [\"utf-8\", \"utf-16le\", \"numpy\", \"binidx\", \"dummy\", \"wds_img\", \"uint16\"]\n    if args.lr_final == 0 or args.lr_init == 0:\n        rank_zero_info(\"\\n\\nNote: lr_final = 0 or lr_init = 0. Using linear LR schedule instead.\\n\\n\")"
        },
        {
            "comment": "This code sets the precision argument, adjusts relevant environment variables and configurations for faster training with different precision types. If using fp32, it provides a note suggesting to use bf16 or tf32 for better performance. It also sets up cudnn settings and allows tf32 in certain precision cases.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4neo/train.py\":281-307",
            "content": "    assert args.precision in [\"fp32\", \"tf32\", \"fp16\", \"bf16\"]\n    os.environ[\"RWKV_FLOAT_MODE\"] = args.precision\n    if args.precision == \"fp32\":\n        for i in range(10):\n            rank_zero_info(\"\\n\\nNote: you are using fp32 (very slow). Try bf16 / tf32 for faster training.\\n\\n\")\n    if args.precision == \"fp16\":\n        rank_zero_info(\"\\n\\nNote: you are using fp16 (might overflow). Try bf16 / tf32 for stable training.\\n\\n\")\n    os.environ[\"RWKV_JIT_ON\"] = \"1\"\n    if \"deepspeed_stage_3\" in args.strategy:\n        os.environ[\"RWKV_JIT_ON\"] = \"0\"\n    torch.backends.cudnn.benchmark = True\n    torch.backends.cudnn.enabled = True\n    if args.precision == \"fp32\":\n        torch.backends.cudnn.allow_tf32 = False\n        torch.backends.cuda.matmul.allow_tf32 = False\n    else:\n        torch.backends.cudnn.allow_tf32 = True\n        torch.backends.cuda.matmul.allow_tf32 = True\n    if \"32\" in args.precision:\n        args.precision = 32\n    elif args.precision == \"fp16\":\n        args.precision = 16\n    else:\n        args.precision = \"bf16\""
        },
        {
            "comment": "Initializing and loading the RWKV model with specified arguments, generating initial weights if none are loaded or if at MyPile stage 1. Saving initial weights in specified directory and then attempting to load pre-trained model from given path.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4neo/train.py\":309-334",
            "content": "    ########################################################################################################\n    from src.trainer import train_callback, generate_init_weight\n    from src.dataset import MyDataset\n    train_data = MyDataset(args)\n    args.vocab_size = train_data.vocab_size\n    if args.data_type == 'wds_img':\n        from src.model_img import RWKV_IMG\n        model = RWKV_IMG(args)\n    else:\n        from src.model import RWKV\n        model = RWKV(args)\n    if len(args.load_model) == 0 or args.my_pile_stage == 1:  # shall we build the initial weights?\n        init_weight_name = f\"{args.proj_dir}/rwkv-init.pth\"\n        generate_init_weight(model, init_weight_name)  # save initial weights\n        args.load_model = init_weight_name\n    rank_zero_info(f\"########## Loading {args.load_model}... ##########\")\n    try:\n        load_dict = torch.load(args.load_model, map_location=\"cpu\")\n        load_keys = list(load_dict.keys())\n        for k in load_keys:\n            if k.startswith('_forward_module.'):"
        },
        {
            "comment": "This code attempts to load a model checkpoint. It first checks if the provided checkpoint file exists, and if not, it tries another one. Then, it loads the dictionary of state parameters from the checkpoint into memory. If loading only part of the model, it also adds missing keys from the original model's state dictionary to the loaded dictionary. Finally, it loads the state dictionary into the model for training or inference.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4neo/train.py\":335-357",
            "content": "                load_dict[k.replace('_forward_module.','')] = load_dict[k]\n                del load_dict[k]\n    except:\n        rank_zero_info(f\"Bad checkpoint {args.load_model}\")\n        if args.my_pile_stage >= 2:  # try again using another checkpoint\n            max_p = args.my_pile_prev_p\n            if max_p == -1:\n                args.load_model = f\"{args.proj_dir}/rwkv-init.pth\"\n            else:\n                args.load_model = f\"{args.proj_dir}/rwkv-{max_p}.pth\"\n            args.epoch_begin = max_p + 1\n            rank_zero_info(f\"Trying {args.load_model}\")\n            load_dict = torch.load(args.load_model, map_location=\"cpu\")\n    if args.load_partial == 1:\n        load_keys = load_dict.keys()\n        for k in model.state_dict():\n            if k not in load_keys:\n                load_dict[k] = model.state_dict()[k]\n    model.load_state_dict(load_dict)\n    if pl.__version__[0]=='2':\n        trainer = Trainer(accelerator=args.accelerator,strategy=args.strategy,devices=args.devices,num_nodes=args.num_nodes,precision=args.precision,"
        },
        {
            "comment": "The code creates a trainer object with specified arguments, including a callback for training. If the model has state dictionaries with shapes larger than 1D, it prints the shape and name of each such dictionary. The code then checks if the strategy used is \"deepspeed\" and sets the bucket size accordingly.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4neo/train.py\":358-377",
            "content": "        logger=args.logger,callbacks=[train_callback(args)],max_epochs=args.max_epochs,check_val_every_n_epoch=args.check_val_every_n_epoch,num_sanity_val_steps=args.num_sanity_val_steps,\n        log_every_n_steps=args.log_every_n_steps,enable_checkpointing=args.enable_checkpointing,accumulate_grad_batches=args.accumulate_grad_batches,gradient_clip_val=args.gradient_clip_val)\n    else:\n        trainer = Trainer.from_argparse_args(\n            args,\n            callbacks=[train_callback(args)],\n        )\n    if trainer.global_rank == 0:\n        for n in model.state_dict():\n            shape = model.state_dict()[n].shape\n            shape = [i for i in shape if i != 1]\n            if len(shape) > 1:\n                print(f\"{str(shape[0]).ljust(5)} {str(shape[1]).ljust(5)} {n}\")\n            else:\n                print(f\"{str(shape[0]).ljust(5)}       {n}\")\n    if \"deepspeed\" in args.strategy:\n        trainer.strategy.config[\"zero_optimization\"][\"allgather_bucket_size\"] = args.ds_bucket_mb * 1000 * 1000\n  "
        },
        {
            "comment": "This code sets the bucket size for zero optimization and configures a data loader with specific parameters before fitting the model in a trainer.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4neo/train.py\":377-382",
            "content": "      trainer.strategy.config[\"zero_optimization\"][\"reduce_bucket_size\"] = args.ds_bucket_mb * 1000 * 1000\n    # must set shuffle=False, persistent_workers=False (because worker is in another thread)\n    data_loader = DataLoader(train_data, shuffle=False, pin_memory=True, batch_size=args.micro_bsz, num_workers=1, persistent_workers=False, drop_last=True)\n    trainer.fit(model, data_loader)"
        }
    ]
}
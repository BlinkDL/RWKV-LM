{
    "summary": "This code defines a Dataset class for the RWKV v2-RNN Language Model, creating token lists and storing them in \"vocab.json\". It provides functions to convert input data into tokens using a pre-defined vocabulary, supports random access to data with fixed epoch length, initializes a word table, sets vocabulary size, establishes dictionaries, refines context, samples logits based on input, sorts probabilities, breaks loop at top_p, calculates cutoff value and modifies probabilities, applies optional temperature parameter, and returns a sample using multinomial sampling.",
    "details": [
        {
            "comment": "This code defines a custom Dataset class for the RWKV v2-RNN Language Model. It builds a token list from input data, stores it in \"vocab.json\", and calculates the dataset size and vocabulary size.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v2-RNN/src/utils.py\":0-32",
            "content": "########################################################################################################\n# The RWKV v2-RNN Language Model - https://github.com/BlinkDL/RWKV-LM\n########################################################################################################\nimport json\nimport random\nimport time\nimport math\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nfrom torch.utils.data import Dataset\nclass Dataset(Dataset):\n    def __init__(self, data, ctx_len, epoch_length_fixed):\n        print('building token list...', end=' ')\n        unique = sorted(list(set(data)))\n        # print()\n        # for u in unique:\n        #     print(u, end=' ')\n        # print('\\n\\n')\n        xx = 0\n        xxObj = {}\n        for u in unique:\n            xxObj[xx] = u\n            xx += 1\n        with open('vocab.json', \"w\", encoding=\"utf-16\") as vocab_file:\n            vocab_file.write(json.dumps(xxObj, ensure_ascii=False))\n        data_size, vocab_size = len(data), len(unique)"
        },
        {
            "comment": "This code defines a class for data processing and loading, with functions to convert input data into tokens using a pre-defined vocabulary. It also provides random access to the data in fixed epoch length. The TOKENIZER class is initialized with a WORD_NAME file path and an UNKNOWN_CHAR placeholder.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v2-RNN/src/utils.py\":33-58",
            "content": "        print('data has %d tokens, %d unique.' % (data_size, vocab_size))\n        self.stoi = {ch: i for i, ch in enumerate(unique)}\n        self.itos = {i: ch for i, ch in enumerate(unique)}\n        self.ctx_len = ctx_len\n        self.epoch_length_fixed = epoch_length_fixed\n        self.vocab_size = vocab_size\n        self.data = data\n    def __len__(self):\n        return self.epoch_length_fixed\n    def __getitem__(self, idx):\n        # cheat: pick a random spot in dataset\n        i = np.random.randint(0, len(self.data) - (self.ctx_len + 1))\n        chunk = self.data[i:i+self.ctx_len+1]\n        dix = [self.stoi[s] for s in chunk]\n        x = torch.tensor(dix[:-1], dtype=torch.long,\n                         device=torch.device('cuda'))\n        y = torch.tensor(dix[1:], dtype=torch.long,\n                         device=torch.device('cuda'))\n        return x, y\nclass TOKENIZER():\n    def __init__(self, WORD_NAME, UNKNOWN_CHAR='\\ue083'):\n        with open(WORD_NAME + '.json', \"r\", encoding=\"utf-16\") as result_file:"
        },
        {
            "comment": "The code initializes a word table, sets vocabulary size, establishes string-to-int and int-to-string dictionaries, defines an UNKNOWN_CHAR, refines context by stripping whitespace and special characters, and samples logits based on input while applying softmax function and considering different top_p values for newline characters.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v2-RNN/src/utils.py\":59-89",
            "content": "            self.word_table = json.load(result_file)\n        self.vocab_size = len(self.word_table)\n        self.stoi = {v: int(k) for k, v in self.word_table.items()}\n        self.itos = {int(k): v for k, v in self.word_table.items()}\n        self.UNKNOWN_CHAR = self.stoi[UNKNOWN_CHAR]\n    def refine_context(self, context):\n        context = context.strip().split('\\n')\n        for c in range(len(context)):\n            context[c] = context[c].strip().strip('\\u3000').strip('\\r')\n        context = list(filter(lambda c: c != '', context))\n        context = '\\n' + ('\\n'.join(context)).strip()\n        if context == '':\n            context = '\\n'\n        return context\n    def sample_logits(self, out, x, ctx_len, temperature=1.0, top_p_usual=None, top_p_newline=None):\n        # out[self.UNKNOWN_CHAR] = -float('Inf')\n        lastChar = int(x[-1])\n        probs = F.softmax(torch.tensor(out), dim=-1)\n        if self.itos[lastChar] == '\\n':\n            top_p = top_p_newline\n        else:\n            top_p = top_p_usual"
        },
        {
            "comment": "Sorts probabilities and breaks loop when cumulative probability exceeds top_p. Calculates a cutoff value based on the sorted probabilities and sets low probabilities to 0. Optionally applies temperature parameter. Returns a single sample from the modified probabilities using multinomial sampling.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v2-RNN/src/utils.py\":91-121",
            "content": "        sorted_probs, s_index = torch.sort(probs, descending=True)\n        # for j in range(30):\n        #     pp = sorted_probs[j].item()\n        #     if pp < 0.005:\n        #         break\n        #     ss = self.itos[int(s_index[j])].replace('\\n','_')\n        #     print(f'{math.floor(pp*100):>3.0f}{ss}', end='')\n        # print('')\n        cumulative_probs = torch.cumsum(sorted_probs, dim=-1).numpy()\n        cutoff = float(sorted_probs[np.argmax(cumulative_probs > top_p)])\n        probs[probs < cutoff] = 0\n        # print(\"[\" + str(round(cutoff,4)) + ' ' + str(round(to_float(sum(probs)),3)) + \"]\", end = \"\")\n        if temperature != 1.0:\n            probs = probs.pow(1.0 / temperature)\n        return torch.multinomial(probs, num_samples=1)[0]\ndef to_float(x):\n    return x.cpu().detach().numpy().flatten()[0].astype(float)\ndef set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)"
        }
    ]
}
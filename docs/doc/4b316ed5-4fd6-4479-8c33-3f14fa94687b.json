{
    "summary": "The code defines 'MMapIndexedDataset' and 'Index' for handling indexed datasets, reading binary data, creating memory-mapped objects, and allows retrieval/manipulation of data. It doesn't support prefetch and checks if files exist for given path.",
    "details": [
        {
            "comment": "This code imports necessary libraries and defines functions for handling indexed datasets. The 'print_rank_0' function prints messages only on rank 0 if distributed is initialized, while '_warmup_mmap_file' warms up an mmap file by reading it in chunks. The 'dtypes' dictionary maps data types to their respective codes. 'index_file_path' and 'data_file_path' functions return the paths for index and data files respectively. The class 'MMapIndexedDataset' inherits from torch.utils.data.Dataset, suggesting it handles indexed datasets in a specific format.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4neo/src/binidx.py\":0-47",
            "content": "from lib2to3.pgen2 import token\nimport os\nimport torch\nimport numpy as np\nimport shutil\nimport struct\nfrom functools import lru_cache\nfrom itertools import accumulate\ndef print_rank_0(*message):\n    pass\n    # \"\"\"If distributed is initialized print only on rank 0.\"\"\"\n    # if torch.distributed.is_initialized():\n    #     if torch.distributed.get_rank() == 0:\n    #         print(*message, flush=True)\n    # else:\n    #     print(*message, flush=True)\ndef _warmup_mmap_file(path):\n    pass\n    # with open(path, \"rb\") as stream:\n    #     while stream.read(100 * 1024 * 1024):\n    #         pass\ndtypes = {\n    1: np.uint8,\n    2: np.int8,\n    3: np.int16,\n    4: np.int32,\n    5: np.int64,\n    6: float,\n    7: np.double,\n    8: np.uint16,\n}\ndef code(dtype):\n    for k in dtypes.keys():\n        if dtypes[k] == dtype:\n            return k\n    raise ValueError(dtype)\ndef index_file_path(prefix_path):\n    return prefix_path + \".idx\"\ndef data_file_path(prefix_path):\n    return prefix_path + \".bin\"\nclass MMapIndexedDataset(torch.utils.data.Dataset):"
        },
        {
            "comment": "The code defines a class called Index with a method writer(). This writer() method creates a subclass _Writer which is used to write the header of a binary file. It writes a magic string, version number (little endian), and data type information in the file.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4neo/src/binidx.py\":48-75",
            "content": "    class Index(object):\n        _HDR_MAGIC = b\"MMIDIDX\\x00\\x00\"\n        @classmethod\n        def writer(cls, path, dtype):\n            class _Writer(object):\n                def __enter__(self):\n                    self._file = open(path, \"wb\")\n                    # Write Magic string so we can check the file format then opening it again.\n                    self._file.write(cls._HDR_MAGIC)\n                    # Write version number\n                    # Little endian unsigned 64 Bit integer\n                    self._file.write(struct.pack(\"<Q\", 1))\n                    # Little endian unsigned 8 Bit integer\n                    self._file.write(struct.pack(\"<B\", code(dtype)))\n                    return self\n                @staticmethod\n                def _get_pointers(sizes):\n                    dtype_size = dtype().itemsize\n                    address = 0\n                    pointers = []\n                    for size in sizes:\n                        pointers.append(address)\n                        address += size * dtype_size"
        },
        {
            "comment": "This code defines a class with methods for writing binary data to a file. The `write` method takes sizes and document index as inputs, writes their lengths as little endian unsigned 64-bit integers, then converts the input arrays to byte sequences in little endian byte order and writes them to the file. The `__exit__` method closes the file when an exception occurs. The `__init__` method initializes an instance with a specified path and optionally skips warmup.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4neo/src/binidx.py\":77-103",
            "content": "                    return pointers\n                def write(self, sizes, doc_idx):\n                    pointers = self._get_pointers(sizes)\n                    # Little endian unsigned 64 Bit integer\n                    self._file.write(struct.pack(\"<Q\", len(sizes)))\n                    # Little endian unsigned 64 Bit integer\n                    self._file.write(struct.pack(\"<Q\", len(doc_idx)))\n                    sizes = np.array(sizes, dtype=np.int32)\n                    self._file.write(sizes.tobytes(order=\"C\"))\n                    del sizes\n                    pointers = np.array(pointers, dtype=np.int64)\n                    self._file.write(pointers.tobytes(order=\"C\"))\n                    del pointers\n                    doc_idx = np.array(doc_idx, dtype=np.int64)\n                    self._file.write(doc_idx.tobytes(order=\"C\"))\n                def __exit__(self, exc_type, exc_val, exc_tb):\n                    self._file.close()\n            return _Writer()\n        def __init__(self, path, skip_warmup=False):"
        },
        {
            "comment": "This code reads the index file and checks its format, version, dtype, size, length, and document count. It then optionally warms up the memory-mapped file for faster access.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4neo/src/binidx.py\":104-127",
            "content": "            with open(path, \"rb\") as stream:\n                magic_test = stream.read(9)\n                assert self._HDR_MAGIC == magic_test, (\n                    \"Index file doesn't match expected format. \"\n                    \"Make sure that --dataset-impl is configured properly.\"\n                )\n                # Little endian unsigned 64 Bit integer\n                version = struct.unpack(\"<Q\", stream.read(8))\n                assert (1,) == version\n                # Little endian unsigned 8 Bit integer\n                (dtype_code,) = struct.unpack(\"<B\", stream.read(1))\n                self._dtype = dtypes[dtype_code]\n                self._dtype_size = self._dtype().itemsize\n                self._len = struct.unpack(\"<Q\", stream.read(8))[0]\n                self._doc_count = struct.unpack(\"<Q\", stream.read(8))[0]\n                offset = stream.tell()\n            if not skip_warmup:\n                print_rank_0(\"    warming up index mmap file...\")\n                _warmup_mmap_file(path)\n            self._bin_buffer_mmap = np.memmap(path, mode=\"r\", order=\"C\")"
        },
        {
            "comment": "This code reads binary data into memory, storing sizes of elements, pointers to each element, and a document index. The buffer is created from a mmap object, and numpy's frombuffer method is used to read the data as int32, int64 types with appropriate counts and offsets. The __del__ method ensures proper cleanup by closing the mmap and deleting it. A dtype property allows access to the type of elements stored.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4neo/src/binidx.py\":128-157",
            "content": "            self._bin_buffer = memoryview(self._bin_buffer_mmap)\n            print_rank_0(\"    reading sizes...\")\n            self._sizes = np.frombuffer(\n                self._bin_buffer, dtype=np.int32, count=self._len, offset=offset\n            )\n            print_rank_0(\"    reading pointers...\")\n            self._pointers = np.frombuffer(\n                self._bin_buffer,\n                dtype=np.int64,\n                count=self._len,\n                offset=offset + self._sizes.nbytes,\n            )\n            print_rank_0(\"    reading document index...\")\n            self._doc_idx = np.frombuffer(\n                self._bin_buffer,\n                dtype=np.int64,\n                count=self._doc_count,\n                offset=offset + self._sizes.nbytes + self._pointers.nbytes,\n            )\n        def __del__(self):\n            self._bin_buffer_mmap._mmap.close()\n            del self._bin_buffer_mmap\n        @property\n        def dtype(self):\n            return self._dtype\n        @property\n        def sizes(self):"
        },
        {
            "comment": "This code defines a class that represents a binary index. It has properties for sizes and document indices, as well as methods for getting items by index and determining the length of the index. The constructor initializes the class instance with a specified path and optionally skips the warmup process. The `__getstate__` and `__setstate__` methods allow saving and restoring the state of the instance, respectively.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4neo/src/binidx.py\":158-195",
            "content": "            return self._sizes\n        @property\n        def doc_idx(self):\n            return self._doc_idx\n        @lru_cache(maxsize=8)\n        def __getitem__(self, i):\n            return self._pointers[i], self._sizes[i]\n        def __len__(self):\n            return self._len\n    def __init__(self, path, skip_warmup=False):\n        super().__init__()\n        self._path = None\n        self._index = None\n        self._bin_buffer = None\n        self._do_init(path, skip_warmup)\n    def __getstate__(self):\n        return self._path\n    def __setstate__(self, state):\n        self._do_init(state)\n    def _do_init(self, path, skip_warmup):\n        self._path = path\n        self._index = self.Index(index_file_path(self._path), skip_warmup)\n        if not skip_warmup:\n            print_rank_0(\"    warming up data mmap file...\")\n            _warmup_mmap_file(data_file_path(self._path))\n        print_rank_0(\"    creating numpy buffer of mmap...\")\n        self._bin_buffer_mmap = np.memmap(\n            data_file_path(self._path), mode=\"r\", order=\"C\""
        },
        {
            "comment": "This code snippet creates a memory view of a numpy buffer, deletes the mmap file and index when object is deleted, provides length of the index, and overrides __getitem__ to return numpy arrays from the buffer based on indices or slices. The LRU cache decorator has been commented out.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4neo/src/binidx.py\":196-225",
            "content": "        )\n        print_rank_0(\"    creating memory view of numpy buffer...\")\n        self._bin_buffer = memoryview(self._bin_buffer_mmap)\n    def __del__(self):\n        self._bin_buffer_mmap._mmap.close()\n        del self._bin_buffer_mmap\n        del self._index\n    def __len__(self):\n        return len(self._index)\n    # @lru_cache(maxsize=8)\n    def __getitem__(self, idx):\n        if isinstance(idx, int):\n            ptr, size = self._index[idx]\n            np_array = np.frombuffer(\n                self._bin_buffer, dtype=self._index.dtype, count=size, offset=ptr\n            )\n            return np_array\n        elif isinstance(idx, slice):\n            start, stop, step = idx.indices(len(self))\n            if step != 1:\n                raise ValueError(\n                    \"Slices into indexed_dataset must be contiguous\")\n            ptr = self._index._pointers[start]\n            sizes = self._index._sizes[idx]\n            offsets = list(accumulate(sizes))\n            total_size = sum(sizes)\n            np_array = np.frombuffer("
        },
        {
            "comment": "The code defines a class with methods to retrieve and manipulate data from an index. The `_bin_buffer` is used to store the binary data, and the `dtype` parameter specifies the data type of the index. The `get()` method retrieves a single item from the dataset and can optionally return only a portion of it. The `sizes` property returns the sizes of the indexed items, while `doc_idx` and related methods are used to set or get the document index.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4neo/src/binidx.py\":226-260",
            "content": "                self._bin_buffer, dtype=self._index.dtype, count=total_size, offset=ptr\n            )\n            sents = np.split(np_array, offsets[:-1])\n            return sents\n    def get(self, idx, offset=0, length=None):\n        \"\"\"Retrieves a single item from the dataset with the option to only\n        return a portion of the item.\n        get(idx) is the same as [idx] but get() does not support slicing.\n        \"\"\"\n        ptr, size = self._index[idx]\n        if length is None:\n            length = size - offset\n        ptr += offset * np.dtype(self._index.dtype).itemsize\n        np_array = np.frombuffer(\n            self._bin_buffer, dtype=self._index.dtype, count=length, offset=ptr\n        )\n        return np_array\n    @property\n    def sizes(self):\n        return self._index.sizes\n    @property\n    def doc_idx(self):\n        return self._index.doc_idx\n    def get_doc_idx(self):\n        return self._index._doc_idx\n    def set_doc_idx(self, doc_idx_):\n        self._index._doc_idx = doc_idx_\n    @property"
        },
        {
            "comment": "Function `supports_prefetch` returns False, indicating it doesn't support prefetch. Function `exists(path)` checks if index and data files exist for given path.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v4neo/src/binidx.py\":261-268",
            "content": "    def supports_prefetch(self):\n        return False\n    @staticmethod\n    def exists(path):\n        return os.path.exists(index_file_path(path)) and os.path.exists(\n            data_file_path(path)\n        )"
        }
    ]
}
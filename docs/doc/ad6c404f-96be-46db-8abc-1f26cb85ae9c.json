{
    "summary": "The CUDA code computes dot products between weight matrix and input data for an RNN model, utilizing shared memory and optimized access. It performs forward pass with iterative dot products and updates variables using input matrices g and k. The code calculates RWKV-v2-RNN time step output and configures backward propagation kernel dimensions in `cuda_backward`.",
    "details": [
        {
            "comment": "Kernel function for forward pass in RWKV-v2-RNN, with CUDA implementation. Uses shared memory to optimize access time. Requires T <= Tmax, B % BF == 0, and B % BB === 0. Initializes ww and kk arrays using w and k parameters, then sets s array to eps for each thread's j in BF. Performs a forward pass on the RNN using shared memory for efficiency.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v2-RNN/cuda/timex_cuda.cu\":0-32",
            "content": "#include <stdio.h>\n// require T <= Tmax, T % 4 == 0, B % BF == 0, B % BB === 0 (Tmax and BF and BB are passed by compiler)\n#define F4(A, B) ((float4 *)(A))[(B) >> 2]\ntemplate <typename F>\n__global__ void kernel_forward(const F *__restrict__ const __w, const F *__restrict__ const __k, F *__restrict__ const x,\n                               const F eps, const int B, const int C, const int T) {\n    const int i = blockIdx.y;\n    const int ij = (B * C) / BF;\n    const int t = threadIdx.x << 2;\n    __shared__ F ww[Tmax];\n    __shared__ F kk[Tmax * BF];\n    F4(ww, t) = F4(__w, t + T * (i % C));\n    #pragma unroll\n    for (int j = 0; j < BF; j++) {\n        F4(kk, t + Tmax * j) = F4(__k, t + T * (i + ij * j));\n    }\n    __syncthreads();\n    float4 s[BF];\n    #pragma unroll\n    for (int j = 0; j < BF; j++) {\n        s[j] = {eps, eps, eps, eps};\n    }\n    const F *__restrict__ const w = ww + T - t - 4;\n    for (int u = 0; u <= t; u++) {\n        #pragma unroll\n        for (int j = 0; j < BF; j++) {\n            const F x = kk[u + Tmax * j];"
        },
        {
            "comment": "This code calculates the dot product between the weight matrix and input data, then updates the output. It performs this operation for each thread and stores the results in shared memory. The kernel function is defined to operate on a specific block of threads, where i represents the block index, and t represents the thread index within that block. The code uses CUDA programming features such as __restrict__ pointers, __global__ functions, and shared memory to optimize performance.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v2-RNN/cuda/timex_cuda.cu\":33-62",
            "content": "            s[j].x += w[u + 3] * x;\n            s[j].y += w[u + 2] * x;\n            s[j].z += w[u + 1] * x;\n            s[j].w += w[u + 0] * x;\n        }\n    }\n    #pragma unroll\n    for (int j = 0; j < BF; j++) {\n        const F *__restrict__ const k = kk + Tmax * j;\n        s[j].y += w[t + 3] * k[t + 1];\n        s[j].z += w[t + 2] * k[t + 1];\n        s[j].z += w[t + 3] * k[t + 2];\n        s[j].w += w[t + 1] * k[t + 1];\n        s[j].w += w[t + 2] * k[t + 2];\n        s[j].w += w[t + 3] * k[t + 3];\n        F4(x, t + T * (i + ij * j)) = s[j];\n    }\n}\ntemplate <typename F>\n__global__ void kernel_backward_W(const F *__restrict__ const __w, const F *__restrict__ const __k, const F *__restrict__ const __gwk,\n                                F *__restrict__ const gw, F *__restrict__ const gk,\n                                const int B, const int C, const int T) {\n    const int i = blockIdx.y;\n    const int t = threadIdx.x << 2;\n    __shared__ F k[Tmax];\n    __shared__ F gg[Tmax];\n    F4(k, t) = F4(__k, t + T * i);\n    F4(gg, t) = F4(__gwk, t + T * i);"
        },
        {
            "comment": "This code performs a forward pass of an RNN model using CUDA. It calculates the output by summing up the contributions from each time step, taking into account the input sequence and the hidden state. The function `cuda_forward` sets up the grid and block dimensions for the kernel launch, while the `kernel_forward` kernel itself performs the actual computation on the GPU.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v2-RNN/cuda/timex_cuda.cu\":63-92",
            "content": "    __syncthreads();\n    float4 s = {0, 0, 0, 0};\n    const F *__restrict__ const g = gg + T - t - 4;\n    for (int u = 0; u <= t; u++) {\n        F x = k[u];\n        s.x += g[u + 3] * x;\n        s.y += g[u + 2] * x;\n        s.z += g[u + 1] * x;\n        s.w += g[u + 0] * x;\n    }\n    s.y += g[t + 3] * k[t + 1];\n    s.z += g[t + 2] * k[t + 1];\n    s.z += g[t + 3] * k[t + 2];\n    s.w += g[t + 1] * k[t + 1];\n    s.w += g[t + 2] * k[t + 2];\n    s.w += g[t + 3] * k[t + 3];\n    F4(gw, t + T * i) = s;\n}\nvoid cuda_forward(const float *w, const float *k, float *x, float eps, int B, int C, int T) {\n    dim3 gridDim(1, B * C / BF);\n    dim3 blockDim(T >> 2);\n    kernel_forward<<<gridDim, blockDim>>>(w, k, x, eps, B, C, T);\n}\ntemplate <typename F>\n__global__ void kernel_backward(const F *__restrict__ const __w, const F *__restrict__ const __k, const F *__restrict__ const __gwk,\n                                F *__restrict__ const gw, F *__restrict__ const gk,\n                                const int B, const int C, const int T) {"
        },
        {
            "comment": "Code initializes shared memory arrays for weights, kernel, and input-kernel product. It then calculates thread-specific weight tensor, loads kernel and input-kernel product into shared memory, and synchronizes threads. Finally, it iteratively performs dot product between shared kernel and input-kernel product tensors to accumulate output tensor values in shared memory.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v2-RNN/cuda/timex_cuda.cu\":93-129",
            "content": "    const int i = blockIdx.y;\n    const int ij = (B * C) / BB;\n    const int t = threadIdx.x << 2;\n    __shared__ F w[Tmax];\n    __shared__ F kk[Tmax * BB];\n    __shared__ F gg[Tmax * BB];\n    F4(w, t) = F4(__w, t + T * (i % C));\n    #pragma unroll\n    for (int j = 0; j < BB; j++) {\n        F4(kk, t + Tmax * j) = F4(__k, t + T * (i + ij * j));\n        F4(gg, t + Tmax * j) = F4(__gwk, t + T * (i + ij * j));\n    }\n    __syncthreads();\n    float4 s[BB];\n    #pragma unroll\n    for (int j = 0; j < BB; j++) {\n        s[j] = {0, 0, 0, 0};\n    }\n    for (int u = 0; u <= t; u++) {\n        #pragma unroll\n        for (int j = 0; j < BB; j++) {\n            const F *__restrict__ const g = gg + Tmax * j + T - t - 4;\n            F x = kk[u + Tmax * j];\n            s[j].x += g[u + 3] * x;\n            s[j].y += g[u + 2] * x;\n            s[j].z += g[u + 1] * x;\n            s[j].w += g[u + 0] * x;\n        }\n    }\n    #pragma unroll\n    for (int j = 0; j < BB; j++) {\n        const F *__restrict__ const k = kk + Tmax * j;\n        const F *__restrict__ const g = gg + Tmax * j + T - t - 4;"
        },
        {
            "comment": "This code updates the values of a set of variables (s[j].x, s[j].y, s[j].z, s[j].w) based on different input matrices g and k. It utilizes unroll to optimize performance by performing multiple calculations simultaneously.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v2-RNN/cuda/timex_cuda.cu\":130-162",
            "content": "        s[j].y += g[t + 3] * k[t + 1];\n        s[j].z += g[t + 2] * k[t + 1];\n        s[j].z += g[t + 3] * k[t + 2];\n        s[j].w += g[t + 1] * k[t + 1];\n        s[j].w += g[t + 2] * k[t + 2];\n        s[j].w += g[t + 3] * k[t + 3];\n        F4(gw, t + T * (i + ij * j)) = s[j];\n    }\n    #pragma unroll\n    for (int j = 0; j < BB; j++) {\n        s[j] = {0, 0, 0, 0};\n    }\n    for (int u = t + 3; u < T; u++) {\n        F x = w[u];\n        #pragma unroll\n        for (int j = 0; j < BB; j++) {\n            const F *__restrict__ const g = gg + Tmax * j + T + t - 3;\n            s[j].x += g[2 - u] * x;\n            s[j].y += g[3 - u] * x;\n            s[j].z += g[4 - u] * x;\n            s[j].w += g[5 - u] * x;\n        }        \n    }\n    #pragma unroll\n    for (int j = 0; j < BB; j++) {\n        const F *__restrict__ const g = gg + Tmax * j + T + t - 3;\n        s[j].x += g[2 - t] * w[t + 0];\n        s[j].x += g[1 - t] * w[t + 1];\n        s[j].x += g[0 - t] * w[t + 2];\n        s[j].y += g[2 - t] * w[t + 1];\n        s[j].y += g[1 - t] * w[t + 2];"
        },
        {
            "comment": "This code snippet is part of the RWKV-v2-RNN implementation in CUDA. It calculates the output of a time step and assigns it to the corresponding location in memory for gradient computation. The `cuda_backward` function configures the grid and block dimensions for a GPU kernel that performs backward propagation on a given dataset.",
            "location": "\"/media/root/Prima/works/RWKV-LM/docs/src/RWKV-v2-RNN/cuda/timex_cuda.cu\":163-171",
            "content": "        s[j].z += g[2 - t] * w[t + 2];\n        F4(gk, t + T * (i + ij * j)) = s[j];\n    }\n}\nvoid cuda_backward(const float *w, const float *k, const float *gwk, float *gw, float *gk, int B, int C, int T) {\n    dim3 gridDim(1, B * C / BB);\n    dim3 blockDim(T >> 2);\n    kernel_backward<<<gridDim, blockDim>>>(w, k, gwk, gw, gk, B, C, T);\n}"
        }
    ]
}